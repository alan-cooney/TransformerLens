Search.setIndex({"docnames": ["content/citation", "content/development", "content/gallery", "content/getting_started", "content/tutorials", "generated/code/modules", "generated/code/transformer_lens", "generated/code/transformer_lens.ActivationCache", "generated/code/transformer_lens.FactoredMatrix", "generated/code/transformer_lens.HookedEncoder", "generated/code/transformer_lens.HookedTransformer", "generated/code/transformer_lens.HookedTransformerConfig", "generated/code/transformer_lens.SVDInterpreter", "generated/code/transformer_lens.components", "generated/code/transformer_lens.evals", "generated/code/transformer_lens.head_detector", "generated/code/transformer_lens.hook_points", "generated/code/transformer_lens.loading_from_pretrained", "generated/code/transformer_lens.past_key_value_caching", "generated/code/transformer_lens.patching", "generated/code/transformer_lens.train", "generated/code/transformer_lens.utilities", "generated/code/transformer_lens.utilities.devices", "generated/code/transformer_lens.utils", "generated/model_properties_table", "index"], "filenames": ["content/citation.md", "content/development.md", "content/gallery.md", "content/getting_started.md", "content/tutorials.md", "generated/code/modules.rst", "generated/code/transformer_lens.rst", "generated/code/transformer_lens.ActivationCache.rst", "generated/code/transformer_lens.FactoredMatrix.rst", "generated/code/transformer_lens.HookedEncoder.rst", "generated/code/transformer_lens.HookedTransformer.rst", "generated/code/transformer_lens.HookedTransformerConfig.rst", "generated/code/transformer_lens.SVDInterpreter.rst", "generated/code/transformer_lens.components.rst", "generated/code/transformer_lens.evals.rst", "generated/code/transformer_lens.head_detector.rst", "generated/code/transformer_lens.hook_points.rst", "generated/code/transformer_lens.loading_from_pretrained.rst", "generated/code/transformer_lens.past_key_value_caching.rst", "generated/code/transformer_lens.patching.rst", "generated/code/transformer_lens.train.rst", "generated/code/transformer_lens.utilities.rst", "generated/code/transformer_lens.utilities.devices.rst", "generated/code/transformer_lens.utils.rst", "generated/model_properties_table.md", "index.md"], "titles": ["Citation", "Local Development", "Gallery", "Getting Started", "Tutorials", "Transformer Lens API", "transformer_lens", "transformer_lens.ActivationCache", "transformer_lens.FactoredMatrix", "transformer_lens.HookedEncoder", "transformer_lens.HookedTransformer", "transformer_lens.HookedTransformerConfig", "transformer_lens.SVDInterpreter", "transformer_lens.components", "transformer_lens.evals", "transformer_lens.head_detector", "transformer_lens.hook_points", "transformer_lens.loading_from_pretrained", "transformer_lens.past_key_value_caching", "transformer_lens.patching", "transformer_lens.train", "transformer_lens.utilities", "transformer_lens.utilities.devices", "transformer_lens.utils", "Model Properties Table", "TransformerLens"], "terms": {"pleas": [0, 1, 3], "cite": 0, "thi": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25], "librari": [0, 1, 2, 3, 4, 14, 23], "misc": 0, "nandatransformerlens2022": 0, "titl": [0, 15], "transformerlen": [0, 1, 3, 4, 7, 10, 13, 17, 23], "author": 0, "nanda": [0, 10], "neel": [0, 4, 10, 12], "url": 0, "http": [0, 3, 4, 10, 11, 13, 14, 15, 19, 23], "github": [0, 1, 3, 4, 10], "com": [0, 3, 4, 10], "neelnanda": [0, 3, 4, 10, 17], "io": [0, 3, 4, 14, 15], "year": 0, "2022": [0, 23], "i": [0, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25], "my": [0, 3, 4, 10, 11, 23, 25], "best": [0, 4, 10], "guess": 0, "how": [0, 3, 4, 7, 10, 15, 19, 20, 25], "softwar": 0, "work": [0, 2, 3, 4, 7, 9, 10, 13, 16, 17, 23, 25], "feel": [0, 25], "free": 0, "send": 0, "correct": [0, 19, 22, 23], "also": [0, 1, 4, 7, 9, 10, 11, 12, 15, 16, 17, 22, 23], "you": [0, 1, 3, 4, 7, 9, 10, 11, 12, 14, 15, 16, 17, 23, 25], "re": [0, 3, 4, 7, 10, 11, 15], "actual": [0, 10, 15, 16], "us": [0, 1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25], "your": [0, 1, 4, 10, 11, 15, 16], "research": [0, 3, 4, 25], "d": [0, 12, 14, 15, 17, 24], "love": 0, "chat": [0, 17, 24], "reach": [0, 10], "out": [0, 3, 4, 10, 12, 19, 23], "neelnanda27": 0, "gmail": 0, "For": [1, 9, 10, 13, 15, 23], "one": [1, 3, 7, 9, 10, 11, 13, 15, 16, 17, 18, 19, 23, 25], "click": 1, "environ": 1, "project": [1, 4, 20], "includ": [1, 4, 7, 9, 10, 11, 14, 15, 16], "It": [1, 3, 4, 7, 9, 10, 11, 14, 16, 19, 23, 25], "can": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 25], "v": [1, 7, 10, 11, 19], "code": [1, 7, 10, 11, 12, 13, 14, 15, 16, 17, 23], "codespac": 1, "poetri": 1, "packag": 1, "manag": [1, 7, 10, 16, 23], "instal": 1, "follow": [1, 10, 23, 25], "virtual": 1, "config": [1, 10, 11, 13, 17, 19, 20], "virtualenv": 1, "true": [1, 7, 9, 10, 11, 14, 15, 16, 17, 19, 22, 23], "dev": 1, "option": [1, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23], "want": [1, 4, 7, 10, 12, 14, 15, 16, 18, 23], "jupyt": 1, "lab": 1, "run": [1, 3, 7, 10, 13, 16, 17, 18, 19, 20, 25], "pip": [1, 3], "jupyterlab": 1, "same": [1, 3, 7, 8, 10, 15, 16, 18, 19, 23], "Then": [1, 19], "import": [1, 3, 10, 12, 14, 15, 18, 19, 25], "transformer_len": [1, 3, 5], "If": [1, 3, 5, 7, 9, 10, 11, 13, 15, 16, 17, 19, 22, 23], "ad": [1, 4, 10, 11, 16], "featur": [1, 3, 4, 9, 12, 19, 23, 25], "add": [1, 10, 11, 13, 16, 18, 23, 25], "unit": 1, "folder": 1, "check": [1, 3, 4, 10, 12, 13, 14, 15, 16, 23], "hasn": [1, 10], "t": [1, 7, 8, 9, 10, 11, 12, 13, 14, 17, 23, 25], "broken": [1, 16], "anyth": [1, 14], "major": 1, "exist": [1, 15], "pytest": 1, "root": [1, 13], "directori": 1, "To": [1, 3, 10, 11, 13, 16, 17], "command": 1, "user": [2, 11, 23], "contribut": [2, 7, 10], "exampl": [2, 9, 10, 12, 13, 23], "being": [2, 7, 9, 10, 11, 15, 16, 19, 23], "action": 2, "induct": [2, 14, 15, 17], "head": [2, 4, 7, 10, 11, 12, 13, 14, 15, 17, 19], "phase": 2, "chang": [2, 3, 10, 11, 16, 17, 19, 23], "replic": [2, 10, 12, 14], "A": [2, 7, 8, 9, 10, 13, 14, 15, 16, 18, 19, 23], "partial": [2, 7], "In": [2, 7, 9, 10, 13, 14, 16], "context": [2, 7, 10, 16, 19, 23], "learn": [2, 3, 4, 11, 20, 23, 25], "from": [2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 23, 25], "connor": 2, "kissan": 2, "decis": [2, 3], "transform": [2, 3, 4, 9, 10, 11, 13, 17, 18, 19, 23], "interpret": [2, 3, 4, 10, 12, 15, 19, 23], "set": [2, 7, 9, 10, 11, 14, 15, 16, 19, 20, 23], "script": [2, 4], "train": [2, 4, 5, 6, 7, 9, 10, 11, 14, 17, 23, 25], "which": [2, 3, 4, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 23], "len": [2, 17], "view": 2, "intermedi": [2, 7, 10, 16], "activ": [2, 3, 4, 7, 9, 10, 11, 12, 16, 19, 23, 25], "perform": [2, 4, 13, 14, 16], "attribut": [2, 4, 7, 19, 23], "ablat": 2, "write": [2, 3, 10, 23, 25], "up": [2, 3, 7, 10, 11, 16, 19, 20], "initi": [2, 5, 10, 11, 16, 22, 23], "found": [2, 10, 11], "here": [2, 7, 10, 11, 13, 14, 15, 23], "main": [3, 4, 16], "demo": [3, 12, 17, 24], "basic": [3, 4, 10, 14, 23], "see": [3, 4, 7, 9, 10, 11, 13, 15, 17, 19, 23, 25], "what": [3, 4, 7, 10, 15, 19, 25], "exploratori": [3, 4, 15, 23, 25], "analysi": [3, 4, 10, 15, 23, 25], "practic": [3, 4], "look": [3, 4, 5, 10, 13, 15, 19], "like": [3, 4, 9, 10, 13, 14, 15, 19, 23, 25], "notebook": [3, 4, 25], "analys": [3, 4, 7, 10], "indirect": [3, 4, 14], "object": [3, 4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 23], "identif": [3, 4, 14], "record": [3, 4], "myself": [3, 4], "do": [3, 4, 7, 9, 10, 13, 14, 16, 19, 23, 25], "mechanist": [3, 4, 19], "veri": [3, 4, 11, 12, 14, 23, 25], "young": 3, "small": [3, 4, 7, 10, 14, 15, 17, 23, 24, 25], "field": [3, 10, 23, 25], "ar": [3, 4, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 23, 25], "lot": [3, 4, 7, 8, 18, 19, 23, 25], "open": [3, 10, 14, 25], "problem": [3, 25], "would": [3, 9, 13, 25], "help": [3, 7, 11, 19], "try": [3, 10, 15], "list": [3, 7, 9, 10, 11, 14, 15, 16, 18, 19, 23], "concret": 3, "figur": [3, 19], "where": [3, 7, 8, 10, 11, 15, 16, 17, 19, 20, 23], "begin": [3, 10, 14, 15, 23], "skill": 3, "kei": [3, 7, 9, 10, 11, 13, 15, 18, 19, 23], "resourc": 3, "new": [3, 4, 7, 10, 16, 17, 18, 23], "tutori": 3, "gpt": [3, 4, 9, 10, 11, 13, 14, 17, 23, 24, 25], "2": [3, 9, 10, 11, 13, 14, 15, 17, 23, 24, 25], "scratch": 3, "an": [3, 4, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25], "accompani": [3, 4], "templat": [3, 14], "yourself": [3, 10], "One": [3, 10, 25], "signific": [3, 16], "design": [3, 7, 25], "made": [3, 14], "wa": [3, 7, 9, 10, 11, 14, 19], "have": [3, 7, 9, 10, 13, 15, 19, 23, 25], "singl": [3, 7, 9, 10, 13, 18, 19, 23], "implement": [3, 9, 10, 19, 23], "could": [3, 7], "support": [3, 4, 9, 10, 11, 15, 16, 23], "rang": [3, 10, 11, 12, 15, 19, 23], "subtli": [3, 13], "differ": [3, 7, 9, 10, 11, 13, 14, 15, 16, 19, 23], "style": [3, 7, 9, 10, 11, 13, 15, 25], "model": [3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23], "ha": [3, 7, 8, 9, 10, 13, 14, 17, 18, 19, 23], "upsid": 3, "just": [3, 7, 10, 11, 14, 19, 23], "arbitrari": [3, 10], "when": [3, 4, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 23], "name": [3, 7, 10, 11, 14, 15, 16, 17, 19, 20, 23], "hookedtransform": [3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 17, 19, 20, 22, 23], "from_pretrain": [3, 9, 10, 12, 14, 15, 17], "But": [3, 7, 10, 19, 23], "downsid": 3, "py": [3, 7, 9], "compon": [3, 5, 6, 7, 9, 10, 23], "difficult": 3, "recommend": [3, 5, 10, 11, 12, 16], "clean": [3, 19, 23], "minim": 3, "intern": [3, 7, 10, 19, 25], "architectur": [3, 9], "significantli": [3, 9, 10, 14, 19], "clearer": 3, "better": [3, 10, 11, 14, 15, 17], "document": [3, 10, 23], "git": 3, "note": [3, 7, 8, 9, 10, 11, 13, 14, 16, 17, 23], "known": [3, 25], "easytransform": [3, 25], "some": [3, 7, 10, 12, 13, 14, 16, 19, 23], "break": [3, 7], "been": [3, 7, 10, 23], "sinc": [3, 7, 10, 13, 16], "renam": 3, "need": [3, 7, 10, 11, 13, 16, 25], "old": [3, 17], "version": [3, 4, 10, 16], "legaci": [3, 15], "v1": 3, "patch": [4, 5, 6], "colab": [4, 25], "googl": 4, "blob": 4, "ipynb": 4, "explain": 4, "techniqu": [4, 10, 19], "causal": [4, 9, 11, 19], "intervent": [4, 19], "identifi": [4, 10, 19], "matter": [4, 10, 19], "produc": [4, 10, 19], "output": [4, 7, 9, 10, 11, 13, 15, 16, 19, 23], "incomplet": 4, "gradient": [4, 7, 16, 20], "take": [4, 7, 10, 13, 16, 19, 23, 25], "linear": [4, 9, 10, 13, 17], "approxim": 4, "": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 25], "good": [4, 7, 14, 23, 25], "individu": [4, 7, 10, 13], "attent": [4, 7, 10, 11, 13, 15, 19, 23], "bad": [4, 10], "larg": [4, 11, 13, 17, 23, 24, 25], "residu": [4, 7, 9, 10, 11, 13, 19], "stream": [4, 7, 9, 10, 11, 13, 19, 23], "probabl": [4, 10, 14, 15, 19, 23], "place": [4, 7, 9, 10], "after": [4, 7, 10, 13, 16, 20, 25], "demonstr": [4, 12], "focus": 4, "less": [4, 10], "rigor": 4, "more": [4, 7, 8, 10, 11, 13, 15, 19, 23, 25], "get": [4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 22, 25], "grasp": 4, "go": [4, 19], "quickli": 4, "logit": [4, 7, 9, 10, 13, 14, 19, 23], "steal": 4, "liber": [4, 16], "grokk": 4, "phenomenon": 4, "memoris": 4, "data": [4, 10, 14, 23], "minimis": 4, "loss": [4, 7, 10, 14, 16, 19, 20, 23], "longer": 4, "generalis": 4, "lead": [4, 7, 9, 16, 23], "sharp": 4, "decreas": [4, 23], "test": [4, 10, 14, 15, 23], "well": [4, 10, 12, 16, 19], "show": [4, 10, 12, 15, 25], "task": [4, 9, 10, 11, 14, 19, 20], "modular": [4, 23], "addit": [4, 9, 10], "verifi": 4, "grok": 4, "The": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25], "light": 4, "explan": [4, 19], "so": [4, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 23], "ll": [4, 10, 15], "pair": [4, 8, 10, 13, 15, 23], "video": 4, "seri": [4, 7], "paper": [4, 10, 11, 13, 14, 19], "base": [4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 24], "detector": [4, 15], "automat": [4, 10, 11, 23], "detect": [4, 15], "sever": [4, 7, 10, 23], "common": [4, 10, 23], "type": [4, 7, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 22, 23], "creat": [4, 10, 13, 16], "own": 4, "custom": [4, 10, 11, 13, 14, 16, 23], "algorithm": [4, 8, 11, 25], "find": [4, 8, 10, 19], "interact": 4, "neuroscop": 4, "hacki": [4, 23], "bug": [4, 7, 11, 23], "web": 4, "visualis": 4, "even": [4, 8, 10, 11, 13, 14, 17, 25], "profession": 4, "front": 4, "end": [4, 10, 16, 19, 23], "develop": 4, "visual": 4, "neuron": [4, 7, 10], "text": [4, 10, 11, 13, 14, 16, 17, 18, 23], "dynam": [4, 11], "updat": [4, 10, 18, 19, 22], "edit": [4, 7, 10, 19, 25], "llama": [4, 17, 24], "convert": [4, 9, 10, 23], "meta": [4, 10, 17, 23], "7b": [4, 17, 24], "paramet": [4, 7, 9, 10, 11, 12, 13, 15, 16, 17, 19, 22, 23], "now": [4, 10], "until": [4, 7, 10, 16], "multi": [4, 23], "gpu": [4, 7, 8, 9, 10], "great": [4, 25], "avail": [4, 10, 11, 15, 17], "access": [4, 11, 16, 23], "gener": [4, 7, 10, 13, 14, 18, 19, 23], "should": [4, 7, 9, 10, 13, 15, 16, 20, 23], "know": [4, 9], "about": [4, 7, 10, 14, 16, 19, 23, 25], "No": 4, "posit": [4, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 23], "experi": [4, 11, 25], "real": [4, 23, 25], "time": [4, 5, 10, 15, 16, 23], "embed": [4, 7, 9, 10, 11, 13], "predict": [4, 9, 10, 13, 14, 15, 23], "previou": [4, 7, 10, 13, 15], "token": [4, 7, 9, 10, 11, 12, 13, 14, 15, 17, 19, 23], "make": [4, 8, 9, 10, 15, 16, 25], "othello": [4, 17, 24], "port": 4, "weight": [4, 7, 9, 10, 11, 13, 20, 25], "excel": [4, 25], "emerg": 4, "world": [4, 25], "represent": 4, "sequenc": [4, 9, 10, 11, 13, 14, 15, 16, 19, 23], "investig": [4, 10, 15], "worth": [4, 7], "read": [4, 10], "interest": [4, 9, 10], "topic": 4, "svd": [4, 8, 10, 12], "conjectur": 4, "post": [4, 7, 12, 13], "singular": [4, 8, 10, 12], "valu": [4, 7, 8, 9, 10, 11, 13, 15, 17, 18, 19, 23, 25], "decomposit": [4, 7, 8, 10], "matric": [4, 8, 10, 12, 13], "surprisingli": 4, "reproduc": [4, 11, 15], "further": [4, 10, 23], "tracr": 4, "cool": 4, "deepmind": 4, "tool": [4, 25], "compil": 4, "written": 4, "program": [4, 25], "rasp": 4, "jax": 4, "form": [4, 7, 8, 10, 19], "pytorch": [4, 10, 11, 16], "brows": 5, "doc": [5, 10, 12], "first": [5, 10, 11, 14, 17, 19, 23], "we": [5, 7, 10, 11, 15, 18, 19, 23, 25], "activationcach": [5, 6, 9, 10, 15, 19, 23], "modul": [5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 23], "submodul": 5, "factoredmatrix": [5, 6, 9, 13, 23], "hookedencod": [5, 6, 22], "hookedtransformerconfig": [5, 6, 10, 13, 17, 18, 22], "svdinterpret": [5, 6], "eval": [5, 6], "head_detector": [5, 6], "hook_point": [5, 6, 10], "loading_from_pretrain": [5, 6, 10], "past_key_value_cach": [5, 6], "util": [5, 6, 7, 8, 10, 15, 16, 17, 20], "subpackag": 5, "cach": [7, 10, 11, 13, 15, 16, 18, 19, 23, 25], "core": [7, 10, 25], "function": [7, 9, 10, 11, 13, 15, 16, 17, 19, 20, 22, 23, 25], "part": [7, 10, 13, 19, 25], "store": [7, 10, 11, 16, 18, 19, 20], "all": [7, 9, 10, 13, 14, 15, 16, 19, 23], "class": [7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 23], "cache_dict": 7, "dict": [7, 9, 10, 11, 13, 14, 15, 16, 23], "str": [7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23], "tensor": [7, 8, 9, 10, 12, 13, 15, 18, 19, 23], "has_batch_dim": 7, "bool": [7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 23], "wrapper": [7, 9, 10, 19, 22], "around": [7, 9, 10, 16, 19, 22], "dictionari": [7, 9, 10, 11, 15, 16, 23], "varieti": 7, "helper": [7, 10, 13, 14, 16, 19, 23], "ani": [7, 9, 10, 11, 13, 16, 23, 25], "specif": [7, 9, 10, 15, 19], "process": [7, 10, 11, 17, 23], "method": [7, 9, 10, 11, 16, 17, 18, 23], "while": [7, 9, 10, 13, 16], "other": [7, 9, 10, 13, 15, 16, 17, 19], "without": [7, 10, 13, 23], "warn": [7, 10, 15, 16, 23], "biggest": 7, "footgun": [7, 16], "sourc": [7, 10, 11, 13, 14, 19, 25], "keep": [7, 10, 16, 25], "track": 7, "index": [7, 10, 11, 13, 17, 19, 22, 23], "dimens": [7, 10, 11, 13, 16, 19, 23], "number": [7, 10, 11, 17, 19, 20, 22, 23], "each": [7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 23], "There": [7, 9, 15, 17, 23, 25], "kind": 7, "attn": [7, 9, 10, 11, 13, 17, 19, 23, 24], "vector": [7, 8, 10, 12, 13, 19], "q": [7, 10, 13, 19], "k": [7, 8, 10, 12, 13, 19, 23], "z": [7, 10, 15, 19], "shape": [7, 9, 10, 13, 19, 23], "batch": [7, 9, 10, 13, 14, 16, 18, 19, 20, 23], "po": [7, 9, 10, 13, 19, 23], "head_index": [7, 10, 12, 13, 19], "d_head": [7, 9, 10, 11, 13, 17, 18, 24], "pattern": [7, 10, 13, 15, 19], "result": [7, 9, 10, 11, 13, 15, 17, 19, 25], "softmax": [7, 10, 13, 23], "attn_scor": [7, 13], "pre": [7, 10, 11, 13, 15, 23], "query_po": [7, 13], "key_po": [7, 13], "d_model": [7, 9, 10, 11, 13, 17, 24], "mlp": [7, 9, 10, 11, 13, 19, 23], "mid": 7, "onli": [7, 8, 9, 10, 11, 13, 15, 16, 17, 23, 24], "solu_ln": [7, 11], "between": [7, 10, 13, 15, 19, 23, 25], "layernorm": [7, 9, 10, 11, 13, 23], "d_mlp": [7, 9, 10, 11, 13, 17, 23, 24], "resid_pr": [7, 11, 13, 19], "resid_mid": [7, 19], "resid_post": [7, 11], "attn_out": [7, 10, 11, 19], "mlp_out": [7, 10, 11, 13, 19], "emb": [7, 13, 23], "pos_emb": [7, 11], "normal": [7, 10, 11, 13, 23, 25], "ln": [7, 10, 11], "lnpre": [7, 11], "scale": [7, 10, 11, 13, 23], "1": [7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 23, 24], "sometim": [7, 14], "miss": 7, "becaus": [7, 8, 9, 10, 11, 13, 14, 23, 25], "appli": [7, 10, 11, 13, 19, 23], "remove_batch_dim": [7, 16, 23], "batch_siz": [7, 9, 13, 14, 16, 18, 20], "robust": 7, "think": [7, 10, 14], "ve": [7, 10, 13, 14, 16, 25], "got": [7, 25], "everyth": [7, 16, 19], "easili": [7, 10, 23], "wrong": [7, 14, 16], "annot": 7, "layers_cov": 7, "layer": [7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23], "queri": [7, 9, 10, 11, 13, 15, 19], "stack": [7, 9, 10, 19, 23], "batch_and_pos_dim": 7, "default": [7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 23], "remov": [7, 8, 10, 16, 23, 25], "slice": [7, 23], "accumulated_resid": 7, "int": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23], "none": [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23], "incl_mid": 7, "fals": [7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 23], "apply_ln": 7, "pos_slic": 7, "union": [7, 9, 10, 12, 13, 15, 16, 18, 19, 22, 23], "tupl": [7, 8, 9, 10, 13, 15, 16, 19, 23], "ndarrai": [7, 10, 23], "mlp_input": [7, 10], "return_label": 7, "float": [7, 8, 9, 10, 11, 13, 15, 17, 18, 19, 20, 23], "accumul": [7, 10], "return": [7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23], "given": [7, 8, 9, 10, 12, 15, 16, 17, 19, 22, 23], "ie": [7, 9, 10, 11, 13, 17, 19, 23], "input": [7, 9, 10, 11, 13, 16, 17, 18, 19, 23], "thought": 7, "gradual": 7, "exclud": [7, 15], "n_layer": [7, 9, 10, 11, 15, 17, 19, 22, 24], "mean": [7, 10, 11, 12, 13, 15, 16, 23], "final": [7, 9, 10, 11, 13, 23], "immedi": [7, 13], "indic": [7, 9, 13, 16, 19, 23], "taken": [7, 10], "give": [7, 10, 11, 14, 17, 19, 23], "l": [7, 10], "whether": [7, 9, 10, 11, 13, 14, 16, 17, 19, 20, 23], "current": [7, 9, 10, 11, 13, 15], "essenti": [7, 10, 25], "rather": [7, 10, 11, 13, 19, 23], "than": [7, 10, 11, 13, 14, 15, 16, 19, 23], "noth": [7, 9, 10, 23], "label": [7, 10, 11, 13, 15, 17], "graph": 7, "num_compon": 7, "apply_ln_to_stack": [7, 10, 23], "residual_stack": 7, "batch_slic": 7, "batch_and_pos_dims_out": 7, "norm": [7, 8, 10, 11, 13, 17, 20], "eg": [7, 10, 14, 19, 23], "decompose_resid": 7, "treat": [7, 10], "them": [7, 10, 13, 16, 19, 23], "factor": [7, 8, 10], "simul": [7, 10], "global": [7, 13, 16, 23], "across": [7, 9, 10, 12, 17, 19, 22], "entir": [7, 10, 19], "element": [7, 10, 13, 15, 19, 23], "why": [7, 13, 23], "doe": [7, 9, 10, 11, 15, 16, 19], "unchang": [7, 9, 10, 23], "torch": [7, 9, 10, 11, 13, 14, 16, 17, 19, 22, 23], "whose": [7, 9, 10, 14, 23], "trail": [7, 8, 23], "assum": [7, 9, 10, 13, 16, 19, 20, 23], "hook_scal": [7, 23], "mai": [7, 9, 10, 11, 23], "0": [7, 9, 10, 11, 12, 13, 15, 17, 20, 23], "unemb": [7, 10, 11, 13], "map": [7, 9, 10, 13, 15, 16], "case": [7, 10, 11, 14, 15, 16, 17, 19, 23, 24], "ln2": [7, 23], "ln1": [7, 11, 23], "must": [7, 9, 10, 11, 13, 14, 15, 16, 23], "ln_final": 7, "over": [7, 10, 19, 23], "full": [7, 9, 10, 11, 13, 23], "alreadi": [7, 10], "detail": [7, 10, 11, 13, 17, 19], "apply_slice_to_batch_dim": 7, "compute_head_result": 7, "comput": [7, 8, 10, 13, 15, 16, 18, 19, 23, 25], "amount": [7, 11], "sum": [7, 8, 10, 11, 13, 15, 23], "plu": 7, "b_o": [7, 9, 10], "intend": [7, 11, 23], "enabl": [7, 10, 25], "use_attn_result": [7, 10, 11], "forget": 7, "mode": [7, 10, 11, 13, 23], "liter": [7, 9, 10, 12, 15, 19], "incl_emb": 7, "decompos": 7, "behaviour": [7, 10], "incl": 7, "get_full_resid_decomposit": 7, "expand_neuron": 7, "bias": [7, 9, 10, 11, 20], "down": [7, 10, 13], "expand": [7, 10], "everi": [7, 9, 10, 13, 16, 19, 20, 23], "get_neuron_result": 7, "neuron_slic": 7, "num_neuron": 7, "e": [7, 9, 10, 13, 15, 16, 17, 23, 24], "much": [7, 10, 14, 15, 19, 23], "subset": [7, 11, 14], "specifi": [7, 9, 10, 11, 14, 15, 16, 22, 23], "expens": [7, 8], "space": [7, 9, 10], "cheap": 7, "axi": [7, 13, 19, 23], "item": [7, 23], "logit_attr": 7, "incorrect_token": 7, "provid": [7, 9, 10, 13, 16, 22, 23], "param": [7, 13, 20], "dure": [7, 16, 18, 25], "stack_activ": 7, "activation_nam": [7, 19], "sublayer_typ": 7, "wai": [7, 10, 16], "exactli": [7, 10, 17], "strictli": 7, "befor": [7, 9, 10, 11, 13, 16, 23], "sub": 7, "pass": [7, 10, 11, 13, 15, 16, 17, 18, 23], "get_act_nam": [7, 23], "infer": [7, 10, 13, 19], "incl_remaind": 7, "term": [7, 10], "rest": [7, 10, 11, 14, 17], "stack_head_result": 7, "length": [7, 9, 10, 11, 13, 23], "x": [7, 10, 13, 15, 16, 17, 23], "n_head": [7, 9, 10, 11, 15, 17, 18, 19, 24], "einop": 7, "notat": 7, "l0h0": 7, "stack_neuron_result": 7, "l0n0": 7, "super": [7, 10, 23], "memori": [7, 8, 9, 10, 11], "short": [7, 23, 25], "devic": [7, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21], "move_model": 7, "move": [7, 9, 10, 19], "mostli": 7, "cpu": [7, 9, 10, 11, 17], "finish": [7, 10, 23], "save": [7, 10, 11, 15, 20, 23], "matmul": 7, "slower": 7, "unless": [7, 10, 11, 14], "toggle_autodiff": 7, "autodiff": 7, "turn": [7, 10], "off": [7, 10, 14], "pretti": [7, 10, 23], "danger": 7, "state": [7, 10, 16, 25], "abil": [7, 19], "complet": [7, 13], "easi": [7, 10, 23, 25], "bunch": [7, 9, 10, 16], "error": [7, 10, 15, 17], "don": [7, 9, 10, 11, 12, 14, 23, 25], "realis": 7, "consum": [7, 8], "downstream": 7, "delet": [7, 23], "stick": 7, "often": [7, 10, 11, 17, 23], "troubl": 7, "its": [7, 10, 16, 25], "mess": [7, 10, 23], "inference_mod": 7, "decor": 7, "achiev": 7, "similar": [7, 9, 10, 13, 15], "effect": [7, 10, 19], "matrix": [8, 9, 10, 12, 13, 15, 23], "repres": [8, 9, 11, 13, 15, 19, 23], "product": [8, 13], "two": [8, 9, 13, 15, 17, 19, 23], "effici": [8, 13, 23], "calcul": [8, 9, 10, 11, 13, 15], "eigenvalu": 8, "ldim": 8, "mdim": 8, "b": [8, 9, 10, 13, 14, 17, 19, 23, 24], "rdim": 8, "low": [8, 10, 13, 23], "rank": [8, 10, 13, 23], "properti": [8, 9, 10, 13, 23], "ab": [8, 10, 15], "leading_dim": [8, 23], "ba": 8, "revers": [8, 19, 23, 25], "sens": [8, 16], "u": [8, 10, 19, 23], "vh": [8, 10], "collapse_l": 8, "collaps": 8, "left": [8, 10, 13, 23, 25], "side": [8, 10], "orthogon": [8, 10], "self": [8, 9, 10, 13], "collapse_r": 8, "analog": 8, "apart": [8, 23], "zero": [8, 10, 15, 23], "bav": 8, "kv": 8, "abav": 8, "kav": 8, "av": 8, "eigenvector": 8, "get_corn": [8, 23], "3": [8, 9, 10, 14, 19, 23, 24, 25], "make_even": 8, "sqrt": [8, 10, 11], "diag": 8, "equival": [8, 10, 13], "factoris": [8, 10, 13], "half": [8, 9, 10, 13, 14], "row": [8, 10, 19], "col": 8, "ndim": 8, "frobeniu": 8, "squar": [8, 13, 23], "m": [8, 23], "st": 8, "transpos": [8, 23], "obviou": [8, 10], "thing": [8, 10, 11, 13, 19, 23, 25], "unsqueez": [8, 23], "hook": [9, 10, 11, 13, 16], "encod": [9, 23], "contain": [9, 10, 13, 14, 15, 16, 17, 18, 23], "bert": [9, 13, 17, 24], "separ": [9, 10, 11, 16, 23], "g": [9, 10, 13, 15, 16, 23], "cfg": [9, 10, 12, 13, 14, 18, 22, 23], "move_to_devic": [9, 10], "kwarg": [9, 10, 15, 17, 23], "hookedrootmodul": [9, 10, 16], "hookpoint": [9, 10, 16], "inherit": 9, "limit": [9, 10], "mvp": 9, "mask": [9, 10, 13, 23], "languag": [9, 10, 13, 14, 20, 23], "mlm": 9, "next": [9, 10, 23], "sentenc": [9, 10, 13, 15], "nsp": 9, "yet": [9, 10, 25], "dropout": 9, "inconsist": [9, 12], "fine": 9, "tune": [9, 17, 23, 24], "pretrain": [9, 10, 11, 14, 17], "load": [9, 10, 11, 14, 17, 23, 25], "via": [9, 10, 19], "few": 9, "might": 9, "preprocess": 9, "fold": [9, 10, 13, 17], "accept": [9, 10, 16], "string": [9, 10, 11, 14, 15, 16, 17, 23], "ov": [9, 10, 12, 13], "qk": [9, 10, 13], "w_e": [9, 10], "d_vocab": [9, 10, 11, 12, 17, 19, 23, 24], "conveni": [9, 10, 11, 16, 23], "w_e_po": [9, 10], "n_ctx": [9, 10, 11, 13, 17, 24], "concaten": [9, 10, 23], "w_po": [9, 10], "overcomplet": [9, 10], "basi": [9, 10], "circuit": [9, 10, 13, 14, 15, 19, 23], "w_k": [9, 10, 11, 13], "w_o": [9, 10, 13], "w_q": [9, 10, 13], "w_u": [9, 10], "unembed": [9, 10], "w_v": [9, 10, 13], "w_in": [9, 10, 12, 13], "w_out": [9, 10, 12, 13], "absolut": [9, 10, 11, 13, 15, 23], "all_head_label": [9, 10], "b_k": [9, 10], "b_q": [9, 10], "b_u": [9, 10], "b_v": [9, 10], "b_in": [9, 10, 13], "b_out": [9, 10, 13], "buffer": [9, 10], "modifi": [9, 10], "cuda": [9, 10, 11, 14, 17], "associ": [9, 10, 16], "call": [9, 10, 11, 13, 16, 17, 23], "construct": 9, "optim": [9, 10, 20], "live": [9, 10], "copi": 9, "forward": [9, 10, 11, 13, 16, 18], "return_typ": [9, 10, 16], "token_type_id": [9, 13], "one_zero_attention_mask": 9, "binari": [9, 13], "id": [9, 10, 13], "belong": [9, 13], "cl": [9, 13], "sep": [9, 13], "typic": [9, 10, 13, 15], "sequence_length": [9, 13, 15, 23], "attend": [9, 11, 13, 23], "ignor": [9, 10, 11, 13, 16, 23], "primarili": 9, "pad": [9, 10, 13, 23], "variabl": 9, "instanc": [9, 13, 15, 16], "shorter": [9, 10], "right": [9, 10, 13, 19, 23], "classmethod": [9, 10, 11, 18], "model_nam": [9, 10, 11, 17], "checkpoint_index": [9, 10, 11, 17], "checkpoint_valu": [9, 10, 11, 17], "hf_model": [9, 10], "dtype": [9, 10, 11, 13, 17, 22], "float32": [9, 10, 11, 13, 17], "from_pretrained_kwarg": [9, 10], "huggingfac": [9, 10, 11, 14, 17, 23, 25], "bertformaskedlm": 9, "unlik": [9, 10, 19], "mp": [9, 10], "run_with_cach": [9, 10, 16], "model_arg": [9, 10, 16], "return_cache_object": [9, 10], "otherwis": [9, 10, 14, 15, 23], "directli": [9, 11, 23], "device_or_dtyp": [9, 10, 22], "print_detail": [9, 10, 22, 23], "cast": [9, 10], "non_block": [9, 10], "memory_format": [9, 10], "channels_last": [9, 10], "Its": [9, 10], "signatur": [9, 10], "point": [9, 10, 11, 12, 16, 23, 25], "complex": [9, 10, 11], "integr": [9, 10, 17], "tri": [9, 10, 25], "asynchron": [9, 10], "respect": [9, 10, 16, 23], "host": [9, 10], "possibl": [9, 10, 15, 19, 23, 25], "pin": [9, 10], "below": [9, 10], "desir": [9, 10], "format": [9, 10, 16], "4d": [9, 10], "keyword": [9, 10, 16], "argument": [9, 10, 11, 16, 17, 23], "xdoctest": [9, 10], "ignore_w": [9, 10], "non": [9, 10, 11, 13, 14, 23], "determinist": [9, 10, 23], "nn": [9, 10, 16], "1913": [9, 10], "3420": [9, 10], "5113": [9, 10], "2325": [9, 10], "doubl": [9, 10], "in_featur": [9, 10], "out_featur": [9, 10], "bia": [9, 10, 11, 13], "float64": [9, 10], "requir": [9, 10, 19, 23], "env": [9, 10], "torch_doctest_cuda1": [9, 10], "gpu1": [9, 10], "1914": [9, 10], "5112": [9, 10], "2324": [9, 10], "float16": [9, 10], "cdoubl": [9, 10], "3741": [9, 10], "j": [9, 10, 11, 13, 17, 24], "2382": [9, 10], "5593": [9, 10], "4443": [9, 10], "complex128": [9, 10], "ones": [9, 10, 15], "6122": [9, 10], "1150": [9, 10], "fairli": 10, "extract": 10, "harder": [10, 19], "aim": [10, 25], "simplifi": 10, "attach": 10, "notabl": [10, 16], "within": [10, 13, 15, 16, 19, 23], "inspect": 10, "alter": 10, "facilit": 10, "deeper": 10, "understand": [10, 15], "pretrainedtokenizerbas": 10, "default_padding_sid": 10, "come": [10, 19], "50": [10, 20], "initialis": [10, 11], "although": [10, 13, 16], "instanti": [10, 11], "randomli": [10, 11], "__init__": [10, 13, 16, 23], "onc": [10, 23], "step": [10, 11, 17, 20, 23], "done": [10, 11, 13, 16], "test_prompt": [10, 23], "w_gate": [10, 13], "gate": [10, 13], "instead": [10, 13, 16], "tokenizer_nam": [10, 11], "cannot": [10, 23], "explicitli": [10, 11, 13, 14, 17, 19], "n_devic": [10, 11, 17, 22], "greater": [10, 15], "split": [10, 13, 17, 23], "multipl": [10, 15, 22, 23], "accumulated_bia": 10, "include_mlp_bias": 10, "layers_accumulated_ov": 10, "all_composition_scor": [10, 23], "composit": 10, "score": [10, 13, 15, 19], "l1": 10, "h1": 10, "l2": 10, "h2": 10, "upper": 10, "triangular": [10, 15, 23], "third": 10, "ax": [10, 19], "pub": [10, 23], "2021": 10, "framework": [10, 13], "html": [10, 23], "20abov": 10, "20diagram": 10, "20show": 10, "20q": 10, "2d": [10, 23], "2c": 10, "20k": [10, 23], "20and": 10, "20v": 10, "2dcomposit": 10, "three": [10, 19, 23], "metric": [10, 15, 19], "center_unemb": 10, "state_dict": 10, "center": [10, 11, 13], "subtract": [10, 15], "themselv": 10, "As": 10, "translat": 10, "invari": 10, "log": [10, 20, 23], "prob": [10, 23], "slightli": 10, "misl": 10, "someth": [10, 14], "center_writing_weight": 10, "fold_layer_norm": [10, 17], "check_hooks_to_add": [10, 16], "hook_point_nam": [10, 16], "dir": [10, 16], "fwd": [10, 16], "is_perman": [10, 16], "prepend": [10, 11, 14, 16, 17, 23], "overrid": [10, 11, 16, 17, 23], "consist": 10, "neighbour": 10, "further_com": [10, 11], "md": [10, 11], "fold_value_bias": 10, "alwai": [10, 11, 19, 23], "constant": 10, "togeth": [10, 23], "doesn": [10, 14], "easier": [10, 14, 25], "formal": 10, "b_o_new": 10, "b_o_origin": 10, "sum_head": 10, "b_v_head": 10, "w_o_head": 10, "loss_per_token": 10, "prepend_bo": [10, 11, 14, 17, 23], "use_default_valu": 10, "padding_sid": [10, 23], "start_at_lay": 10, "shortformer_pos_emb": [10, 13], "attention_mask": [10, 13, 18, 23], "stop_at_lay": 10, "past_kv_cach": [10, 13], "hookedtransformerkeyvaluecach": [10, 13, 18], "both": [10, 15, 16, 18], "either": [10, 15, 16, 17, 19], "flag": [10, 11, 14, 16, 19, 23], "standard": [10, 11], "cross": [10, 23], "entropi": [10, 23], "per": [10, 19, 23], "averag": [10, 14], "scalar": [10, 16], "bo": [10, 11, 15, 17, 23], "impli": 10, "usag": 10, "default_prepend_bo": [10, 11, 14, 17, 23], "accordingli": [10, 11, 13, 17], "lose": [10, 11, 17], "inform": [10, 11, 13, 16, 17], "empir": [10, 11, 17, 19], "seem": [10, 11, 14, 17], "local": [10, 11, 13, 17, 23], "start": [10, 19], "inclus": 10, "skip": 10, "neg": [10, 23], "block": [10, 11, 12, 13, 19, 23], "shortform": [10, 11, 13, 17], "positional_embedding_typ": [10, 11, 13], "stop": 10, "exclus": [10, 23], "etc": [10, 19, 25], "24": [10, 24], "frozen": [10, 18], "pai": 10, "repeat": [10, 14, 18, 23], "through": 10, "correctli": 10, "okai": 10, "twice": [10, 14], "accid": 10, "second": [10, 14], "prompt": [10, 14, 19, 23], "fold_ln": [10, 17], "refactor_factored_attn_matric": 10, "automodelforcausallm": 10, "most": [10, 16, 23, 25], "autoregress": [10, 20], "gpt2": [10, 11, 12, 13, 14, 15, 17, 24], "neo": [10, 13, 17, 24], "gptj": [10, 17], "opt": [10, 17, 24], "toi": 10, "solu": [10, 11, 17, 23, 24], "under": 10, "checkpoint": [10, 11, 17, 20], "stanford": [10, 11, 13, 17, 24], "crfm": [10, 17], "load_and_process_state_dict": 10, "tini": [10, 17, 24], "stori": [10, 17, 19, 24], "1m": [10, 17, 24], "official_model_nam": [10, 17], "alia": [10, 17, 23], "subsequ": [10, 17], "regular": 10, "batchnorm": 10, "mathemat": [10, 13], "w_": 10, "b_": 10, "w": 10, "layernormpr": [10, 13], "eff": 10, "ext": 10, "wise": [10, 15], "computation": 10, "merg": 10, "handl": 10, "wish": 10, "defin": [10, 13, 16], "x_1": 10, "x_0": 10, "x_2": 10, "frac": 10, "x_3": 10, "cdot": 10, "x_4": 10, "refer": [10, 13, 16], "due": 10, "relat": 10, "idea": [10, 19, 25], "preced": 10, "direct": [10, 12, 16, 19], "never": 10, "w_write": 10, "dim": [10, 23], "keepdim": 10, "affect": [10, 19], "fed": [10, 15], "1000": [10, 14, 23], "recreat": 10, "onto": [10, 17], "By": [10, 14, 16, 17, 19, 23], "els": [10, 11, 13, 17], "mix": [10, 23], "linearli": 10, "technic": 10, "deriv": 10, "h": 10, "broadcast_b_v": 10, "broadcast": 10, "And": [10, 19], "destination_posit": 10, "source_posit": 10, "along": [10, 13, 23], "source_": 10, "multipli": [10, 13, 15], "remain": [10, 16], "destin": [10, 11, 19], "behavior": [10, 11, 17], "cache_dir": [10, 23], "torch_dtyp": 10, "compat": [10, 17], "especi": 10, "bfloat16": 10, "from_pretrained_no_process": 10, "boolean": [10, 16, 19, 23], "max_new_token": 10, "10": [10, 12, 23, 24], "stop_at_eo": 10, "eos_token_id": [10, 23], "do_sampl": 10, "top_k": [10, 23], "top_p": [10, 23], "temperatur": [10, 23], "freq_penalti": [10, 23], "num_return_sequ": 10, "use_past_kv_cach": 10, "verbos": 10, "pos_plus_new_token": 10, "sampl": [10, 23], "eos_token": 10, "avoid": [10, 18, 23], "fiddl": 10, "rag": 10, "eot": 10, "throw": 10, "awai": 10, "enter": [10, 25], "messi": 10, "size": [10, 11, 13, 20, 23], "maximum": [10, 11, 20], "stable_lm": 10, "distribut": [10, 22, 23], "greedi": [10, 23], "search": [10, 15], "max": 10, "mass": 10, "top": [10, 23], "cumul": [10, 23], "higher": 10, "random": [10, 11, 14, 20], "temp": [10, 23], "inf": 10, "uniform": [10, 23], "frequenc": [10, 23], "penalti": [10, 23], "penalis": 10, "speed": 10, "applic": 10, "whatev": 10, "tqdm": 10, "progress": 10, "bar": 10, "get_token_posit": 10, "single_token": 10, "rais": [10, 15, 17, 23], "present": 10, "gotcha": [10, 12], "Be": 10, "care": [10, 13, 16], "weird": [10, 11], "carefulli": 10, "correspond": [10, 15, 19, 23], "dummi": [10, 16], "match": [10, 15], "last": [10, 23], "init_weight": [10, 11], "std": 10, "initializer_rang": [10, 11], "02": [10, 17], "roughli": [10, 14], "scheme": 10, "truncat": [10, 14, 23], "halv": 10, "empti": [10, 16], "thei": [10, 11, 13, 14, 19, 23, 25], "bulk": 10, "seed": [10, 11, 20], "ensur": 10, "determin": [10, 13, 19, 22, 23], "NOT": [10, 16, 23], "far": [10, 23], "tell": [10, 14], "date": 10, "gotten": 10, "round": [10, 14], "issu": 10, "18182": 10, "transformerencod": 10, "exact": 10, "72253": 10, "mup": 10, "haven": 10, "those": [10, 16, 23], "arxiv": [10, 11, 13, 14], "org": [10, 11, 13, 14, 25], "2203": 10, "03466": 10, "input_to_emb": 10, "relev": [10, 11, 13, 19, 23], "special": 10, "redwood": 10, "2l": [10, 17, 24], "load_sample_training_dataset": 10, "dataset": [10, 14, 20, 23], "10k": [10, 14, 23], "get_dataset": [10, 23], "appropri": 10, "info": [10, 11, 19, 23], "download": [10, 23], "locat": [10, 19], "pt": 10, "openwebtext": [10, 14, 23], "link": [10, 14], "karma": [10, 14], "reddit": [10, 14], "hard": 10, "pile": [10, 14, 17, 23, 24], "cover": 10, "imperfectli": 10, "suppli": 10, "valid": [10, 14], "loss_fn": 10, "per_token": [10, 23], "lm_cross_entropy_loss": [10, 23], "move_model_modules_to_devic": 10, "process_weights_": 10, "allow": [10, 15, 19, 23], "cleaner": 10, "experiment": 10, "argu": 10, "somewhat": 10, "w_qk": [10, 13], "w_ov": [10, 13], "mani": [10, 13, 18, 19, 20], "hopefulli": [10, 25], "attempt": 10, "column": [10, 19, 23], "rotat": [10, 11, 13], "nth": 10, "formula": 10, "r": 10, "setup": [10, 16, 19], "refactor": 10, "diagon": 10, "asymmetri": 10, "fiddli": 10, "deal": [10, 13, 23], "preserv": 10, "too": [10, 19], "bilinear": 10, "y": [10, 15], "dimension": [10, 11], "coordin": 10, "sample_datapoint": 10, "implicitli": [10, 19], "manual": [10, 23], "replac": [10, 11, 19, 25], "choic": 10, "set_token": [10, 11], "pretrainedtoken": 10, "set_use_attn_in": 10, "use_attn_in": [10, 11], "toggl": 10, "set_use_attn_result": 10, "expos": [10, 25], "burn": 10, "set_use_hook_mlp_in": 10, "use_hook_mlp_in": [10, 11], "set_use_split_qkv_input": 10, "use_split_qkv_input": [10, 11], "to_single_str_token": 10, "int_token": 10, "to_single_token": 10, "uncertain": 10, "to_token": [10, 23], "to_str_token": [10, 12], "weirdli": 10, "therefor": 10, "sure": [10, 23], "were": [10, 11, 14, 25], "gotcha2": 10, "depend": 10, "letter": 10, "capit": 10, "shoot": 10, "foot": 10, "gotcha3": 10, "exce": 10, "str_token": 10, "to_str": 10, "numpi": [10, 11, 23], "arrai": [10, 12, 23], "long": 10, "window": [10, 11, 23], "tokens_to_residual_direct": 10, "dot": [10, 13, 23], "mislead": 10, "incorrect": [10, 19], "integ": [10, 23], "residual_direct": 10, "namedtupl": 10, "dataclass": [11, 16], "configur": [11, 20, 22], "act_fn": [11, 24], "ep": 11, "1e": [11, 17], "05": [11, 17], "use_attn_scal": 11, "use_local_attn": 11, "original_architectur": 11, "from_checkpoint": 11, "checkpoint_label_typ": 11, "window_s": [11, 13], "attn_typ": [11, 13], "init_mod": 11, "normalization_typ": 11, "attention_dir": 11, "attn_onli": [11, 24], "scale_attn_by_inverse_layer_idx": 11, "final_rm": 11, "d_vocab_out": [11, 13], "parallel_attn_mlp": 11, "rotary_dim": [11, 13], "n_param": [11, 24], "use_hook_token": 11, "gated_mlp": 11, "tokenizer_prepends_bo": 11, "AND": 11, "feedforward": 11, "network": 11, "4": [11, 14, 23, 24], "vocabulari": 11, "vocab": 11, "lowercas": 11, "relu": [11, 24], "gelu": [11, 13, 17, 24], "silu": [11, 24], "gelu_new": [11, 23], "gelu_fast": [11, 23], "epsilon": 11, "5": [11, 14, 15, 19, 23, 24], "THEN": 11, "intens": 11, "famili": 11, "certain": [11, 19], "distanc": 11, "back": [11, 13], "weight_init_mod": 11, "pipelin": 11, "parallel": [11, 23], "respons": 11, "aka": 11, "unidirect": 11, "bidirect": 11, "python": [11, 12, 14, 23], "deviat": 11, "8": [11, 14, 15, 24], "layer_id": [11, 13], "mistral": [11, 14, 17], "numer": [11, 12, 13], "stabil": [11, 13], "fp16": 11, "rotari": [11, 13], "describ": [11, 23], "blog": [11, 13], "eleuth": [11, 13, 23], "ai": [11, 13, 23], "res_stream": 11, "sinusoid": 11, "rmsnorm": [11, 13], "dumb": 11, "origin": [11, 12], "equal": 11, "mainli": 11, "curs": 11, "hidden": 11, "law": 11, "pdf": [11, 13, 14], "2001": 11, "08361": 11, "meaning": [11, 19], "Will": [11, 19, 23], "let": [11, 23, 25], "interven": [11, 16, 19], "add_bos_token": [11, 23], "control": [11, 19], "from_dict": 11, "config_dict": 11, "set_seed_everywher": 11, "to_dict": 11, "get_singular_vector": 12, "vector_typ": 12, "layer_index": 12, "num_vector": 12, "particular": [12, 15], "plot": 12, "pysvelt": 12, "instabl": 12, "build": [12, 16, 25], "docsfrom": 12, "docsmodel": 12, "medium": [12, 17, 24], "docssvd_interpret": 12, "docsov": 12, "svd_interpret": 12, "22": [12, 14], "docsall_token": 12, "np": [12, 23], "all_token": 12, "docsdef": 12, "plot_matrix": 12, "filter": [12, 16, 17, 23], "topk": 12, "topktabl": 12, "obj_typ": 12, "docsplot_matrix": 12, "pure": 13, "glossari": 13, "order": [13, 19, 23], "sorri": 13, "underli": [13, 19], "destination_residu": 13, "destination_po": 13, "source_po": 13, "convent": 13, "256": [13, 24], "Not": 13, "moment": 13, "mistal": 13, "reason": 13, "apply_causal_mask": 13, "pos_plus_past_kv_pos_offset": 13, "past_kv_pos_offset": [13, 23], "offset_po": [13, 23], "apply_rotari": 13, "calculate_sin_cos_rotari": 13, "10000": 13, "sine": 13, "cosin": 13, "wave": 13, "inexplic": 13, "adjac": 13, "neox": [13, 17, 24], "n": [13, 20, 23], "clue": 13, "resolv": 13, "query_input": 13, "key_input": 13, "value_input": 13, "past_kv_cache_entri": 13, "hookedtransformerkeyvaluecacheentri": [13, 18], "additive_attention_mask": 13, "irrelev": 13, "entri": [13, 18, 19], "past": [13, 18], "rotate_every_two": 13, "x0": 13, "x1": 13, "bertblock": 13, "transformerblock": 13, "except": 13, "overridden": [13, 16, 23], "subclass": [13, 16], "recip": [13, 16], "afterward": [13, 16], "former": [13, 16], "regist": [13, 16], "latter": [13, 16], "silent": [13, 16], "bertemb": 13, "input_id": 13, "bertmlmhead": 13, "purpos": [13, 14], "resid": 13, "gatedmlp": 13, "equat": 13, "pre_linear": 13, "normalis": 13, "posemb": 13, "rm": 13, "rmsnormpr": 13, "tokentypeemb": 13, "1810": 13, "04805": 13, "block_index": 13, "positional_embeddings_typ": 13, "_description_": 13, "_type_": [13, 16], "evalu": [14, 16], "rough": 14, "properli": 14, "howev": 14, "cheapli": 14, "compar": [14, 25], "baselin": 14, "ioidataset": 14, "noun": 14, "num_sampl": 14, "symmetr": 14, "2211": 14, "00593": 14, "ioi_ev": 14, "print": [14, 20, 23], "100": 14, "476": 14, "met": 14, "gave": 14, "alic": 14, "bob": 14, "charli": 14, "ball": 14, "book": 14, "397": 14, "static": 14, "get_default_nam": 14, "get_default_noun": 14, "get_default_templ": 14, "get_sampl": 14, "evaluate_on_dataset": 14, "data_load": 14, "induction_loss": 14, "subseq_len": 14, "384": 14, "measur": [14, 15, 19, 23], "longtensor": 14, "accuraci": [14, 15, 23], "make_code_data_load": 14, "codeparrot": [14, 23], "dump": 14, "lower": [14, 15, 23], "presum": 14, "natur": 14, "make_owt_data_load": 14, "corpu": [14, 23], "make_pile_data_load": 14, "eleutherai": [14, 17], "english": [14, 25], "academ": 14, "internet": 14, "content": 14, "make_wiki_data_load": 14, "wikitext": 14, "wikipedia": [14, 23], "articl": [14, 23], "larger": 14, "realli": [14, 15], "expect": [14, 15], "anyon": 14, "bother": 14, "quarantin": 14, "nowadai": 14, "leakag": 14, "though": [14, 23], "believ": 14, "sanity_check": 14, "feed": [14, 23], "paragraph": 14, "zoom": [14, 19], "quick": [14, 15], "saniti": 14, "ok": 14, "7": [14, 24], "gone": 14, "compute_head_attention_similarity_scor": 15, "attention_pattern": 15, "detection_pattern": 15, "exclude_bo": 15, "exclude_current_token": 15, "error_measur": 15, "mul": 15, "omit": 15, "comparison": 15, "exclude_bcurrent_token": 15, "detect_head": 15, "seq": [15, 23], "previous_token_head": 15, "duplicate_token_head": 15, "induction_head": 15, "headnam": 15, "itself": [15, 23], "quantifi": 15, "divid": [15, 23], "straightforward": 15, "big": [15, 17, 23], "fraction": 15, "alloc": 15, "prohibit": 15, "disabl": [15, 16], "cours": 15, "raw": 15, "interv": 15, "perfect": 15, "mismatch": 15, "precis": [15, 19], "examin": 15, "switch": 15, "advantag": 15, "closer": 15, "head_nam": 15, "ioi": 15, "spacifi": 15, "analyz": 15, "paid": 15, "plotli": 15, "express": 15, "px": 15, "def": 15, "imshow": 15, "render": 15, "xaxi": 15, "yaxi": 15, "to_numpi": [15, 23], "color_continuous_midpoint": 15, "color_continuous_scal": 15, "rdbu": 15, "attention_scor": 15, "zmin": 15, "zmax": 15, "get_duplicate_token_head_detection_pattern": 15, "duplic": 15, "dynalist": 15, "n2zwtnoyhru1s4vnfsaq519j": 15, "2ukvedzonghl5uhugvhroxeo": 15, "get_induction_head_detection_pattern": 15, "_tfvup5csv5orithmqwj0gsi": 15, "get_previous_token_head_detection_pattern": 15, "0o5vohe9xezn8ertywkh7ioc": 15, "get_supported_head": 15, "inspir": [16, 25], "garcon": [16, 25], "act": [16, 19, 23], "ident": [16, 23], "wrap": 16, "add_hook": 16, "level": [16, 25], "fn": 16, "hook_nam": 16, "add_perma_hook": 16, "clear_context": 16, "remove_hook": 16, "including_perman": 16, "arg": 16, "interfac": [16, 25], "nice": 16, "variou": 16, "run_with_hook": 16, "temporari": [16, 23], "persist": 16, "debug": [16, 17, 20], "fix": 16, "still": 16, "solv": [16, 25], "api": 16, "intent": 16, "reset_hook": 16, "accident": 16, "goe": 16, "backward": 16, "reset_hooks_end": 16, "add_caching_hook": 16, "names_filt": 16, "callabl": [16, 19], "incl_bwd": 16, "namesfilt": 16, "lambda": 16, "cache_al": 16, "cache_som": 16, "check_and_add_hook": 16, "get_caching_hook": 16, "fwd_hook": 16, "bwd_hook": 16, "exit": [16, 23], "clear": 16, "whenev": 16, "reset": 16, "my_hook": 16, "hooked_loss": 16, "remove_all_hook_fn": 16, "model_kwarg": 16, "degrad": 16, "lenshandl": 16, "removablehandl": 16, "context_level": 16, "hold": 16, "perman": 16, "hug": 17, "face": 17, "hub": [17, 23], "768": [17, 24], "layer_norm_ep": 17, "50257": [17, 24], "init_rang": 17, "1024": [17, 23, 24], "64": [17, 24], "3072": [17, 24], "12": [17, 24], "model_alias": 17, "arthurconmi": 17, "redwood_attn_2l": [17, 24], "baidicoot": 17, "6b": [17, 24], "3b": [17, 24], "125m": [17, 24], "20b": [17, 24], "pythia": [17, 24], "4b": [17, 24], "dedup": [17, 24], "v0": [17, 24], "12b": [17, 24], "13b": [17, 24], "14m": [17, 24], "160m": [17, 24], "seed1": [17, 24], "seed2": [17, 24], "seed3": [17, 24], "1b": [17, 24], "800m": 17, "8b": [17, 24], "31m": [17, 24], "410m": [17, 24], "350m": 17, "6": [17, 23, 24], "9b": [17, 24], "70m": [17, 24], "19m": [17, 24], "hf": 17, "2l512w": 17, "lr": [17, 20], "attn_only_1l512w_c4_cod": 17, "1l": [17, 24], "c4": [17, 23], "attn_only_2l512w_c4_cod": 17, "attn_only_3l512w_c4_cod": 17, "3l": [17, 24], "attn_only_4l512w_c4_cod": 17, "4l": [17, 24], "gelu_1l512w_c4_cod": 17, "gelu_2l512w_c4_cod": 17, "gelu_3l512w_c4_cod": 17, "gelu_4l512w_c4_cod": 17, "solu_10l1280w_c4_cod": 17, "10l": [17, 24], "solu_10l_v22_old": 17, "solu_12l1536w_c4_cod": 17, "12l": [17, 24], "solu_12l_v23_old": 17, "solu_1l512w_c4_cod": 17, "solu_1l512w_wiki_finetun": 17, "wiki": [17, 23, 24], "finetun": 17, "solu_1l_v9_old": 17, "solu_2l512w_c4_cod": 17, "solu_2l_v10_old": 17, "solu_3l512w_c4_cod": 17, "solu_4l512w_c4_cod": 17, "solu_4l512w_wiki_finetun": 17, "solu_4l_v11_old": 17, "solu_6l768w_c4_cod": 17, "6l": [17, 24], "solu_6l_v13_old": 17, "solu_8l1024w_c4_cod": 17, "8l": [17, 24], "solu_8l_v21_old": 17, "distilgpt2": 17, "distillgpt2": [17, 24], "distil": 17, "facebook": 17, "xxl": 17, "30b": [17, 24], "xxxl": 17, "xl": [17, 24], "66b": [17, 24], "xxxxl": 17, "65b": [17, 24], "roneneldan": 17, "tinystori": 17, "1layer": 17, "21m": [17, 24], "28m": [17, 24], "2layer": 17, "33m": [17, 24], "3m": [17, 24], "8m": [17, 24], "instruct": [17, 24], "instuct": 17, "stabilityai": 17, "stablelm": [17, 24], "alpha": [17, 24], "x21": 17, "arwen": 17, "battlestar": 17, "x49": 17, "beren": 17, "caprica": 17, "x81": 17, "c": [17, 23, 24], "celebrimbor": 17, "darkmatt": 17, "x343": 17, "durin": 17, "eowyn": 17, "x777": 17, "expans": 17, "alias": 17, "offici": 17, "get_checkpoint_label": 17, "label_typ": 17, "get_num_params_of_pretrain": 17, "suffici": 17, "get_pretrained_model_config": 17, "automodel": 17, "autoconfig": 17, "me": [17, 25], "aren": 17, "infrastructur": [17, 25], "ourselv": [18, 25], "previous_attention_mask": 18, "pos_so_far": 18, "append": 18, "prefix": 18, "append_attention_mask": 18, "new_token": 18, "freez": 18, "init_cach": 18, "unfreez": 18, "past_kei": 18, "jaxtyp": 18, "past_valu": 18, "new_kei": 18, "new_valu": 18, "init_cache_entri": 18, "structur": 19, "generic_activation_patch": 19, "specialis": 19, "introduc": 19, "rome": 19, "baulab": 19, "_": 19, "shift": 19, "answer": [19, 23], "corrupt": 19, "continu": 19, "toward": 19, "iter": [19, 23], "increas": 19, "localis": 19, "__from__": 19, "__to": 19, "__the": 19, "confid": 19, "intuit": 19, "diffus": 19, "spread": 19, "connect": 19, "ultim": 19, "engin": [19, 25], "least": 19, "tend": 19, "extrem": [19, 25], "eiffel": 19, "tower": 19, "pari": 19, "factual": 19, "recal": 19, "colosseum": 19, "anywher": 19, "corrupted_token": 19, "clean_cach": 19, "patching_metr": 19, "patch_sett": 19, "index_axis_nam": 19, "src_po": 19, "dest_po": 19, "index_df": 19, "datafram": 19, "return_index_df": 19, "studi": 19, "counterfactu": 19, "index_to_act_nam": 19, "recov": 19, "panda": 19, "diff": 19, "corrupted_activ": 19, "chunk": 19, "fulli": 19, "fill": 19, "flatten": 19, "patched_output": 19, "get_act_patch_attn_head_all_pos_everi": 19, "patch_typ": 19, "get_act_patch_attn_head_by_pos_everi": 19, "get_act_patch_attn_head_k_all_po": 19, "corruptedactiv": 19, "patchedactiv": 19, "layer_head_vector_patch_sett": 19, "axisnam": 19, "pd": 19, "get_act_patch_attn_head_k_by_po": 19, "layer_pos_head_vector_patch_sett": 19, "get_act_patch_attn_head_out_all_po": 19, "get_act_patch_attn_head_out_by_po": 19, "get_act_patch_attn_head_pattern_all_po": 19, "layer_head_pattern_patch_sett": 19, "get_act_patch_attn_head_pattern_by_po": 19, "layer_head_pos_pattern_patch_sett": 19, "get_act_patch_attn_head_pattern_dest_src_po": 19, "layer_head_dest_src_pos_pattern_patch_sett": 19, "get_act_patch_attn_head_q_all_po": 19, "get_act_patch_attn_head_q_by_po": 19, "get_act_patch_attn_head_v_all_po": 19, "get_act_patch_attn_head_v_by_po": 19, "get_act_patch_attn_out": 19, "layer_pos_patch_sett": 19, "get_act_patch_block_everi": 19, "get_act_patch_mlp_out": 19, "get_act_patch_resid_mid": 19, "get_act_patch_resid_pr": 19, "clean_activ": 19, "hookedtransformertrainconfig": 20, "num_epoch": 20, "001": 20, "momentum": 20, "max_grad_norm": 20, "weight_decai": 20, "optimizer_nam": 20, "adam": 20, "warmup_step": 20, "save_everi": 20, "save_dir": 20, "wandb": 20, "wandb_project_nam": 20, "print_everi": 20, "max_step": 20, "hyperparamet": [20, 23], "epoch": 20, "rate": 20, "decai": 20, "warmup": 20, "wandb_project": 20, "termin": 20, "assist": 22, "get_device_for_block_index": 22, "target": 22, "move_to_and_update_config": 22, "vari": 23, "throughout": 23, "locallyoverridendefault": 23, "restor": 23, "overriden": 23, "input_slic": 23, "syntax": 23, "reduc": 23, "extra": 23, "leav": 23, "elif": 23, "1d": 23, "sliceinput": 23, "valueerror": 23, "abov": 23, "max_ctx": 23, "int32": 23, "int64": 23, "select": 23, "composition_scor": 23, "broadcast_dim": 23, "leading_dims_left_and_right": 23, "download_file_from_hf": 23, "repo_nam": 23, "file_nam": 23, "subfold": 23, "home": 23, "runner": 23, "force_is_torch": 23, "file": 23, "json": 23, "path": 23, "pth": 23, "extens": 23, "layer_typ": 23, "shorthand": 23, "feedback": [23, 25], "loop": [23, 25], "hack": 23, "stuff": 23, "readabl": 23, "digit": 23, "word": 23, "k6": 23, "scale4ln1": 23, "appear": 23, "distinguish": 23, "hook_k": 23, "hook_pr": 23, "hook_emb": 23, "27": 23, "hook_norm": 23, "pre5": 23, "get_attention_mask": 23, "leftmost": 23, "rightmost": 23, "consid": 23, "get_cumsum_along_dim": 23, "dataset_nam": 23, "explor": 23, "000": 23, "enorm": 23, "100gb": 23, "2tb": 23, "effort": 23, "dataload": 23, "fanci": 23, "data_dir": 23, "approx": 23, "co": 23, "ton": [23, 25], "divers": 23, "coloss": 23, "crawl": 23, "bigger": 23, "c4_code": 23, "friendli": 23, "ratio": 23, "22m": 23, "5m": 23, "20220301": 23, "en": 23, "get_devic": 23, "get_input_with_manually_prepended_bo": 23, "autotoken": 23, "get_nested_attr": 23, "obj": 23, "attr_str": 23, "retriev": 23, "nest": 23, "hierarchi": 23, "get_offset_position_id": 23, "offset": 23, "get_tokenizer_with_bo": 23, "Such": 23, "llamatoken": 23, "get_tokens_with_bos_remov": 23, "is_lower_triangular": 23, "is_squar": 23, "keep_single_column": 23, "col_nam": 23, "lm_accuraci": 23, "seq_len": 23, "altern": 23, "override_or_use_default_valu": 23, "default_flag": 23, "print_gpu_mem": 23, "step_nam": 23, "sample_logit": 23, "final_logit": 23, "vocab_s": 23, "high": 23, "argmaxi": 23, "encourag": 23, "9": [23, 24], "90": 23, "renormalis": 23, "mutual": 23, "neither": 23, "proport": 23, "input_token": 23, "todo": 23, "edg": 23, "randn": 23, "uniqu": 23, "return_count": 23, "set_nested_attr": 23, "prepend_space_to_answ": 23, "tokenize_and_concaten": 23, "max_length": 23, "column_nam": 23, "num_proc": 23, "eo": 23, "reshap": 23, "____": 23, "drop": 23, "faster": 23, "parallelis": 23, "chop": 23, "20": [23, 24], "privileg": 23, "earli": 23, "cnn": 23, "bos_token_id": 23, "swap": 23, "regardless": 23, "85m": 24, "302m": 24, "16": 24, "4096": 24, "708m": 24, "36": 24, "1280": 24, "5120": 24, "5b": 24, "48": 24, "1600": 24, "25": 24, "6400": 24, "42m": 24, "2048": 24, "50272": 24, "2b": 24, "32": 24, "8192": 24, "2560": 24, "80": 24, "10240": 24, "128": 24, "16384": 24, "40": 24, "20480": 24, "7168": 24, "56": 24, "28672": 24, "9216": 24, "72": 24, "36864": 24, "28": 24, "50400": 24, "44": 24, "6144": 24, "50432": 24, "96": 24, "24576": 24, "2m": 24, "50304": 24, "512": 24, "7m": 24, "805m": 24, "11b": 24, "50688": 24, "13m": 24, "50278": 24, "736": 24, "11": 24, "2944": 24, "101m": 24, "197m": 24, "340m": 24, "1536": 24, "48262": 24, "4m": 24, "0m": 24, "50277": 24, "524k": 24, "50259": 24, "0b": 24, "32000": 24, "11008": 24, "13824": 24, "25b": 24, "60": 24, "6656": 24, "52": 24, "17920": 24, "50b": 24, "22016": 24, "25m": 24, "59": 24, "61": 24, "28996": 24, "393k": 24, "6m": 24, "formerli": 25, "goal": 25, "fact": 25, "todai": 25, "speak": 25, "human": 25, "palm": 25, "nor": 25, "offend": 25, "greatli": 25, "principl": 25, "fun": 25, "ml": 25, "gap": 25, "plai": 25, "flow": 25, "transfer": 25, "anthrop": 25, "team": 25, "wrote": 25, "independ": 25, "frustrat": 25, "deepspe": 25, "littl": 25, "dig": 25, "industri": 25, "heavili": 25, "credit": 25, "nelson": 25, "elhag": 25, "chri": 25, "olah": 25}, "objects": {"transformer_lens": [[7, 0, 0, "-", "ActivationCache"], [8, 0, 0, "-", "FactoredMatrix"], [9, 0, 0, "-", "HookedEncoder"], [10, 0, 0, "-", "HookedTransformer"], [11, 0, 0, "-", "HookedTransformerConfig"], [12, 0, 0, "-", "SVDInterpreter"], [13, 0, 0, "-", "components"], [14, 0, 0, "-", "evals"], [15, 0, 0, "-", "head_detector"], [16, 0, 0, "-", "hook_points"], [17, 0, 0, "-", "loading_from_pretrained"], [18, 0, 0, "-", "past_key_value_caching"], [19, 0, 0, "-", "patching"], [20, 0, 0, "-", "train"], [23, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[7, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[7, 2, 1, "", "accumulated_resid"], [7, 2, 1, "", "apply_ln_to_stack"], [7, 2, 1, "", "apply_slice_to_batch_dim"], [7, 2, 1, "", "compute_head_results"], [7, 2, 1, "", "decompose_resid"], [7, 2, 1, "", "get_full_resid_decomposition"], [7, 2, 1, "", "get_neuron_results"], [7, 2, 1, "", "items"], [7, 2, 1, "", "keys"], [7, 2, 1, "", "logit_attrs"], [7, 2, 1, "", "remove_batch_dim"], [7, 2, 1, "", "stack_activation"], [7, 2, 1, "", "stack_head_results"], [7, 2, 1, "", "stack_neuron_results"], [7, 2, 1, "", "to"], [7, 2, 1, "", "toggle_autodiff"], [7, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[8, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[8, 3, 1, "", "AB"], [8, 3, 1, "", "BA"], [8, 3, 1, "", "S"], [8, 3, 1, "", "T"], [8, 3, 1, "", "U"], [8, 3, 1, "", "Vh"], [8, 2, 1, "", "collapse_l"], [8, 2, 1, "", "collapse_r"], [8, 3, 1, "", "eigenvalues"], [8, 2, 1, "", "get_corner"], [8, 2, 1, "", "make_even"], [8, 3, 1, "", "ndim"], [8, 2, 1, "", "norm"], [8, 3, 1, "", "pair"], [8, 2, 1, "", "svd"], [8, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[9, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[9, 3, 1, "", "OV"], [9, 3, 1, "", "QK"], [9, 3, 1, "", "W_E"], [9, 3, 1, "", "W_E_pos"], [9, 3, 1, "", "W_K"], [9, 3, 1, "", "W_O"], [9, 3, 1, "", "W_Q"], [9, 3, 1, "", "W_U"], [9, 3, 1, "", "W_V"], [9, 3, 1, "", "W_in"], [9, 3, 1, "", "W_out"], [9, 3, 1, "", "W_pos"], [9, 2, 1, "", "all_head_labels"], [9, 3, 1, "", "b_K"], [9, 3, 1, "", "b_O"], [9, 3, 1, "", "b_Q"], [9, 3, 1, "", "b_U"], [9, 3, 1, "", "b_V"], [9, 3, 1, "", "b_in"], [9, 3, 1, "", "b_out"], [9, 2, 1, "", "cpu"], [9, 2, 1, "", "cuda"], [9, 2, 1, "", "forward"], [9, 2, 1, "", "from_pretrained"], [9, 2, 1, "", "mps"], [9, 2, 1, "", "run_with_cache"], [9, 2, 1, "", "to"]], "transformer_lens.HookedTransformer": [[10, 1, 1, "", "HookedTransformer"], [10, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[10, 3, 1, "", "OV"], [10, 3, 1, "", "QK"], [10, 3, 1, "", "W_E"], [10, 3, 1, "", "W_E_pos"], [10, 3, 1, "", "W_K"], [10, 3, 1, "", "W_O"], [10, 3, 1, "", "W_Q"], [10, 3, 1, "", "W_U"], [10, 3, 1, "", "W_V"], [10, 3, 1, "", "W_gate"], [10, 3, 1, "", "W_in"], [10, 3, 1, "", "W_out"], [10, 3, 1, "", "W_pos"], [10, 2, 1, "", "__init__"], [10, 2, 1, "", "accumulated_bias"], [10, 2, 1, "", "all_composition_scores"], [10, 2, 1, "", "all_head_labels"], [10, 3, 1, "", "b_K"], [10, 3, 1, "", "b_O"], [10, 3, 1, "", "b_Q"], [10, 3, 1, "", "b_U"], [10, 3, 1, "", "b_V"], [10, 3, 1, "", "b_in"], [10, 3, 1, "", "b_out"], [10, 2, 1, "", "center_unembed"], [10, 2, 1, "", "center_writing_weights"], [10, 2, 1, "", "check_hooks_to_add"], [10, 2, 1, "", "cpu"], [10, 2, 1, "", "cuda"], [10, 2, 1, "", "fold_layer_norm"], [10, 2, 1, "", "fold_value_biases"], [10, 2, 1, "", "forward"], [10, 2, 1, "", "from_pretrained"], [10, 2, 1, "", "from_pretrained_no_processing"], [10, 2, 1, "", "generate"], [10, 2, 1, "", "get_token_position"], [10, 2, 1, "", "init_weights"], [10, 2, 1, "", "input_to_embed"], [10, 2, 1, "", "load_and_process_state_dict"], [10, 2, 1, "", "load_sample_training_dataset"], [10, 2, 1, "", "loss_fn"], [10, 2, 1, "", "move_model_modules_to_device"], [10, 2, 1, "", "mps"], [10, 2, 1, "", "process_weights_"], [10, 2, 1, "", "refactor_factored_attn_matrices"], [10, 2, 1, "", "run_with_cache"], [10, 2, 1, "", "sample_datapoint"], [10, 2, 1, "", "set_tokenizer"], [10, 2, 1, "", "set_use_attn_in"], [10, 2, 1, "", "set_use_attn_result"], [10, 2, 1, "", "set_use_hook_mlp_in"], [10, 2, 1, "", "set_use_split_qkv_input"], [10, 2, 1, "", "to"], [10, 2, 1, "", "to_single_str_token"], [10, 2, 1, "", "to_single_token"], [10, 2, 1, "", "to_str_tokens"], [10, 2, 1, "", "to_string"], [10, 2, 1, "", "to_tokens"], [10, 2, 1, "", "tokens_to_residual_directions"]], "transformer_lens.HookedTransformer.Output": [[10, 4, 1, "", "logits"], [10, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[11, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[11, 4, 1, "", "act_fn"], [11, 4, 1, "", "attention_dir"], [11, 4, 1, "", "attn_only"], [11, 4, 1, "", "attn_types"], [11, 4, 1, "", "checkpoint_index"], [11, 4, 1, "", "checkpoint_label_type"], [11, 4, 1, "", "checkpoint_value"], [11, 4, 1, "", "d_head"], [11, 4, 1, "", "d_mlp"], [11, 4, 1, "", "d_model"], [11, 4, 1, "", "d_vocab"], [11, 4, 1, "", "d_vocab_out"], [11, 4, 1, "", "default_prepend_bos"], [11, 4, 1, "", "device"], [11, 4, 1, "", "dtype"], [11, 4, 1, "", "eps"], [11, 4, 1, "", "final_rms"], [11, 4, 1, "", "from_checkpoint"], [11, 2, 1, "", "from_dict"], [11, 4, 1, "", "gated_mlp"], [11, 4, 1, "", "init_mode"], [11, 4, 1, "", "init_weights"], [11, 4, 1, "", "initializer_range"], [11, 4, 1, "", "model_name"], [11, 4, 1, "", "n_ctx"], [11, 4, 1, "", "n_devices"], [11, 4, 1, "", "n_heads"], [11, 4, 1, "", "n_layers"], [11, 4, 1, "", "n_params"], [11, 4, 1, "", "normalization_type"], [11, 4, 1, "", "original_architecture"], [11, 4, 1, "", "parallel_attn_mlp"], [11, 4, 1, "", "positional_embedding_type"], [11, 4, 1, "", "rotary_dim"], [11, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [11, 4, 1, "", "seed"], [11, 2, 1, "", "set_seed_everywhere"], [11, 2, 1, "", "to_dict"], [11, 4, 1, "", "tokenizer_name"], [11, 4, 1, "", "tokenizer_prepends_bos"], [11, 4, 1, "", "use_attn_in"], [11, 4, 1, "", "use_attn_result"], [11, 4, 1, "", "use_attn_scale"], [11, 4, 1, "", "use_hook_mlp_in"], [11, 4, 1, "", "use_hook_tokens"], [11, 4, 1, "", "use_local_attn"], [11, 4, 1, "", "use_split_qkv_input"], [11, 4, 1, "", "window_size"]], "transformer_lens.SVDInterpreter": [[12, 1, 1, "", "SVDInterpreter"]], "transformer_lens.SVDInterpreter.SVDInterpreter": [[12, 2, 1, "", "get_singular_vectors"]], "transformer_lens.components": [[13, 1, 1, "", "Attention"], [13, 1, 1, "", "BertBlock"], [13, 1, 1, "", "BertEmbed"], [13, 1, 1, "", "BertMLMHead"], [13, 1, 1, "", "Embed"], [13, 1, 1, "", "GatedMLP"], [13, 1, 1, "", "LayerNorm"], [13, 1, 1, "", "LayerNormPre"], [13, 1, 1, "", "MLP"], [13, 1, 1, "", "PosEmbed"], [13, 1, 1, "", "RMSNorm"], [13, 1, 1, "", "RMSNormPre"], [13, 1, 1, "", "TokenTypeEmbed"], [13, 1, 1, "", "TransformerBlock"], [13, 1, 1, "", "Unembed"]], "transformer_lens.components.Attention": [[13, 3, 1, "", "OV"], [13, 3, 1, "", "QK"], [13, 2, 1, "", "__init__"], [13, 2, 1, "", "apply_causal_mask"], [13, 2, 1, "", "apply_rotary"], [13, 2, 1, "", "calculate_sin_cos_rotary"], [13, 2, 1, "", "forward"], [13, 2, 1, "", "rotate_every_two"]], "transformer_lens.components.BertBlock": [[13, 2, 1, "", "forward"]], "transformer_lens.components.BertEmbed": [[13, 2, 1, "", "forward"]], "transformer_lens.components.BertMLMHead": [[13, 2, 1, "", "forward"]], "transformer_lens.components.Embed": [[13, 2, 1, "", "forward"]], "transformer_lens.components.GatedMLP": [[13, 2, 1, "", "forward"]], "transformer_lens.components.LayerNorm": [[13, 2, 1, "", "__init__"], [13, 2, 1, "", "forward"]], "transformer_lens.components.LayerNormPre": [[13, 2, 1, "", "__init__"], [13, 2, 1, "", "forward"]], "transformer_lens.components.MLP": [[13, 2, 1, "", "forward"]], "transformer_lens.components.PosEmbed": [[13, 2, 1, "", "forward"]], "transformer_lens.components.RMSNorm": [[13, 2, 1, "", "__init__"], [13, 2, 1, "", "forward"]], "transformer_lens.components.RMSNormPre": [[13, 2, 1, "", "__init__"], [13, 2, 1, "", "forward"]], "transformer_lens.components.TokenTypeEmbed": [[13, 2, 1, "", "forward"]], "transformer_lens.components.TransformerBlock": [[13, 2, 1, "", "forward"]], "transformer_lens.components.Unembed": [[13, 2, 1, "", "forward"]], "transformer_lens.evals": [[14, 1, 1, "", "IOIDataset"], [14, 5, 1, "", "evaluate"], [14, 5, 1, "", "evaluate_on_dataset"], [14, 5, 1, "", "induction_loss"], [14, 5, 1, "", "ioi_eval"], [14, 5, 1, "", "make_code_data_loader"], [14, 5, 1, "", "make_owt_data_loader"], [14, 5, 1, "", "make_pile_data_loader"], [14, 5, 1, "", "make_wiki_data_loader"], [14, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[14, 2, 1, "", "get_default_names"], [14, 2, 1, "", "get_default_nouns"], [14, 2, 1, "", "get_default_templates"], [14, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[15, 5, 1, "", "compute_head_attention_similarity_score"], [15, 5, 1, "", "detect_head"], [15, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [15, 5, 1, "", "get_induction_head_detection_pattern"], [15, 5, 1, "", "get_previous_token_head_detection_pattern"], [15, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[16, 1, 1, "", "HookPoint"], [16, 1, 1, "", "HookedRootModule"], [16, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[16, 2, 1, "", "add_hook"], [16, 2, 1, "", "add_perma_hook"], [16, 2, 1, "", "clear_context"], [16, 2, 1, "", "forward"], [16, 2, 1, "", "layer"], [16, 2, 1, "", "remove_hooks"]], "transformer_lens.hook_points.HookedRootModule": [[16, 2, 1, "", "add_caching_hooks"], [16, 2, 1, "", "add_hook"], [16, 2, 1, "", "add_perma_hook"], [16, 2, 1, "", "cache_all"], [16, 2, 1, "", "cache_some"], [16, 2, 1, "", "check_and_add_hook"], [16, 2, 1, "", "check_hooks_to_add"], [16, 2, 1, "", "clear_contexts"], [16, 2, 1, "", "get_caching_hooks"], [16, 2, 1, "", "hook_points"], [16, 2, 1, "", "hooks"], [16, 2, 1, "", "remove_all_hook_fns"], [16, 2, 1, "", "reset_hooks"], [16, 2, 1, "", "run_with_cache"], [16, 2, 1, "", "run_with_hooks"], [16, 2, 1, "", "setup"]], "transformer_lens.hook_points.LensHandle": [[16, 4, 1, "id0", "context_level"], [16, 4, 1, "id1", "hook"], [16, 4, 1, "id2", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[17, 1, 1, "", "Config"], [17, 6, 1, "", "MODEL_ALIASES"], [17, 6, 1, "", "OFFICIAL_MODEL_NAMES"], [17, 5, 1, "", "get_checkpoint_labels"], [17, 5, 1, "", "get_num_params_of_pretrained"], [17, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[17, 4, 1, "", "d_head"], [17, 4, 1, "", "d_mlp"], [17, 4, 1, "", "d_model"], [17, 4, 1, "", "d_vocab"], [17, 4, 1, "", "debug"], [17, 4, 1, "", "init_range"], [17, 4, 1, "", "layer_norm_eps"], [17, 4, 1, "", "n_ctx"], [17, 4, 1, "", "n_heads"], [17, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[18, 1, 1, "", "HookedTransformerKeyValueCache"], [18, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[18, 2, 1, "", "append_attention_mask"], [18, 4, 1, "", "entries"], [18, 2, 1, "", "freeze"], [18, 4, 1, "", "frozen"], [18, 2, 1, "", "init_cache"], [18, 4, 1, "", "previous_attention_mask"], [18, 2, 1, "", "unfreeze"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[18, 2, 1, "", "append"], [18, 4, 1, "", "frozen"], [18, 2, 1, "", "init_cache_entry"], [18, 4, 1, "", "past_keys"], [18, 4, 1, "", "past_values"]], "transformer_lens.patching": [[19, 5, 1, "", "generic_activation_patch"], [19, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [19, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [19, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [19, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [19, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [19, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [19, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [19, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [19, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [19, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [19, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [19, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [19, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [19, 5, 1, "", "get_act_patch_attn_out"], [19, 5, 1, "", "get_act_patch_block_every"], [19, 5, 1, "", "get_act_patch_mlp_out"], [19, 5, 1, "", "get_act_patch_resid_mid"], [19, 5, 1, "", "get_act_patch_resid_pre"], [19, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [19, 5, 1, "", "layer_head_pattern_patch_setter"], [19, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [19, 5, 1, "", "layer_head_vector_patch_setter"], [19, 5, 1, "", "layer_pos_head_vector_patch_setter"], [19, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.train": [[20, 1, 1, "", "HookedTransformerTrainConfig"], [20, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[20, 4, 1, "", "batch_size"], [20, 4, 1, "", "device"], [20, 4, 1, "", "lr"], [20, 4, 1, "", "max_grad_norm"], [20, 4, 1, "", "max_steps"], [20, 4, 1, "", "momentum"], [20, 4, 1, "", "num_epochs"], [20, 4, 1, "", "optimizer_name"], [20, 4, 1, "", "print_every"], [20, 4, 1, "", "save_dir"], [20, 4, 1, "", "save_every"], [20, 4, 1, "", "seed"], [20, 4, 1, "", "wandb"], [20, 4, 1, "", "wandb_project_name"], [20, 4, 1, "", "warmup_steps"], [20, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[22, 0, 0, "-", "devices"]], "transformer_lens.utilities.devices": [[22, 5, 1, "", "get_device_for_block_index"], [22, 5, 1, "", "move_to_and_update_config"]], "transformer_lens.utils": [[23, 1, 1, "", "LocallyOverridenDefaults"], [23, 1, 1, "", "Slice"], [23, 6, 1, "", "SliceInput"], [23, 5, 1, "", "composition_scores"], [23, 5, 1, "", "download_file_from_hf"], [23, 5, 1, "", "gelu_fast"], [23, 5, 1, "", "gelu_new"], [23, 5, 1, "", "get_act_name"], [23, 5, 1, "", "get_attention_mask"], [23, 5, 1, "", "get_corner"], [23, 5, 1, "", "get_cumsum_along_dim"], [23, 5, 1, "", "get_dataset"], [23, 5, 1, "", "get_device"], [23, 5, 1, "", "get_input_with_manually_prepended_bos"], [23, 5, 1, "", "get_nested_attr"], [23, 5, 1, "", "get_offset_position_ids"], [23, 5, 1, "", "get_tokenizer_with_bos"], [23, 5, 1, "", "get_tokens_with_bos_removed"], [23, 5, 1, "", "is_lower_triangular"], [23, 5, 1, "", "is_square"], [23, 5, 1, "", "keep_single_column"], [23, 5, 1, "", "lm_accuracy"], [23, 5, 1, "", "lm_cross_entropy_loss"], [23, 5, 1, "", "override_or_use_default_value"], [23, 5, 1, "", "print_gpu_mem"], [23, 5, 1, "", "remove_batch_dim"], [23, 5, 1, "", "sample_logits"], [23, 5, 1, "", "set_nested_attr"], [23, 5, 1, "", "solu"], [23, 5, 1, "", "test_prompt"], [23, 5, 1, "", "to_numpy"], [23, 5, 1, "", "tokenize_and_concatenate"], [23, 5, 1, "", "transpose"]], "transformer_lens.utils.LocallyOverridenDefaults": [[23, 2, 1, "", "__init__"]], "transformer_lens.utils.Slice": [[23, 2, 1, "", "__init__"], [23, 2, 1, "", "apply"], [23, 2, 1, "", "indices"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "local": 1, "develop": 1, "devcontain": 1, "manual": 1, "setup": 1, "test": 1, "galleri": 2, "get": 3, "start": [3, 4], "advic": 3, "read": 3, "code": 3, "instal": 3, "tutori": 4, "where": 4, "To": 4, "demo": 4, "transform": 5, "len": 5, "api": 5, "content": 5, "transformer_len": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "submodul": [6, 21], "subpackag": 6, "activationcach": 7, "factoredmatrix": 8, "hookedencod": 9, "hookedtransform": 10, "hookedtransformerconfig": 11, "svdinterpret": 12, "compon": 13, "eval": 14, "head_detector": 15, "hook_point": 16, "loading_from_pretrain": 17, "past_key_value_cach": 18, "patch": 19, "train": 20, "util": [21, 22, 23], "devic": 22, "model": [24, 25], "properti": 24, "tabl": 24, "transformerlen": 25, "A": 25, "librari": 25, "mechanist": 25, "interpret": 25, "gener": 25, "languag": 25}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Local Development": [[1, "local-development"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Tutorials": [[4, "tutorials"]], "Where To Start": [[4, "where-to-start"]], "Demos": [[4, "demos"]], "Transformer Lens API": [[5, "transformer-lens-api"]], "Contents": [[5, "contents"]], "transformer_lens": [[6, "transformer-lens"]], "Submodules": [[6, "submodules"], [21, "submodules"]], "Subpackages": [[6, "subpackages"]], "transformer_lens.ActivationCache": [[7, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix": [[8, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder": [[9, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedTransformer": [[10, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig": [[11, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.SVDInterpreter": [[12, "module-transformer_lens.SVDInterpreter"]], "transformer_lens.components": [[13, "module-transformer_lens.components"]], "transformer_lens.evals": [[14, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[15, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[16, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[17, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[18, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[19, "module-transformer_lens.patching"]], "transformer_lens.train": [[20, "module-transformer_lens.train"]], "transformer_lens.utilities": [[21, "transformer-lens-utilities"]], "transformer_lens.utilities.devices": [[22, "module-transformer_lens.utilities.devices"]], "transformer_lens.utils": [[23, "module-transformer_lens.utils"]], "Model Properties Table": [[24, "model-properties-table"]], "TransformerLens": [[25, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[25, "a-library-for-mechanistic-interpretability-of-generative-language-models"]]}, "indexentries": {"activationcache (class in transformer_lens.activationcache)": [[7, "transformer_lens.ActivationCache.ActivationCache"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "items() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.items"]], "keys() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.keys"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "module": [[7, "module-transformer_lens.ActivationCache"], [8, "module-transformer_lens.FactoredMatrix"], [9, "module-transformer_lens.HookedEncoder"], [10, "module-transformer_lens.HookedTransformer"], [11, "module-transformer_lens.HookedTransformerConfig"], [12, "module-transformer_lens.SVDInterpreter"], [13, "module-transformer_lens.components"], [14, "module-transformer_lens.evals"], [15, "module-transformer_lens.head_detector"], [16, "module-transformer_lens.hook_points"], [17, "module-transformer_lens.loading_from_pretrained"], [18, "module-transformer_lens.past_key_value_caching"], [19, "module-transformer_lens.patching"], [20, "module-transformer_lens.train"], [22, "module-transformer_lens.utilities.devices"], [23, "module-transformer_lens.utils"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "to() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.to"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "transformer_lens.activationcache": [[7, "module-transformer_lens.ActivationCache"]], "values() (transformer_lens.activationcache.activationcache method)": [[7, "transformer_lens.ActivationCache.ActivationCache.values"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "transformer_lens.factoredmatrix": [[8, "module-transformer_lens.FactoredMatrix"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[8, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[9, "transformer_lens.HookedEncoder.HookedEncoder"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "mps() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.mps"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[9, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "transformer_lens.hookedencoder": [[9, "module-transformer_lens.HookedEncoder"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[10, "transformer_lens.HookedTransformer.HookedTransformer"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "output (class in transformer_lens.hookedtransformer)": [[10, "transformer_lens.HookedTransformer.Output"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_gate (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_gate"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "__init__() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.__init__"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "input_to_embed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.input_to_embed"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[10, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[10, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "mps() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.mps"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "transformer_lens.hookedtransformer": [[10, "module-transformer_lens.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "default_prepend_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.default_prepend_bos"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "dtype (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.dtype"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokenizer_prepends_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_prepends_bos"]], "transformer_lens.hookedtransformerconfig": [[11, "module-transformer_lens.HookedTransformerConfig"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[11, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "svdinterpreter (class in transformer_lens.svdinterpreter)": [[12, "transformer_lens.SVDInterpreter.SVDInterpreter"]], "get_singular_vectors() (transformer_lens.svdinterpreter.svdinterpreter method)": [[12, "transformer_lens.SVDInterpreter.SVDInterpreter.get_singular_vectors"]], "transformer_lens.svdinterpreter": [[12, "module-transformer_lens.SVDInterpreter"]], "attention (class in transformer_lens.components)": [[13, "transformer_lens.components.Attention"]], "bertblock (class in transformer_lens.components)": [[13, "transformer_lens.components.BertBlock"]], "bertembed (class in transformer_lens.components)": [[13, "transformer_lens.components.BertEmbed"]], "bertmlmhead (class in transformer_lens.components)": [[13, "transformer_lens.components.BertMLMHead"]], "embed (class in transformer_lens.components)": [[13, "transformer_lens.components.Embed"]], "gatedmlp (class in transformer_lens.components)": [[13, "transformer_lens.components.GatedMLP"]], "layernorm (class in transformer_lens.components)": [[13, "transformer_lens.components.LayerNorm"]], "layernormpre (class in transformer_lens.components)": [[13, "transformer_lens.components.LayerNormPre"]], "mlp (class in transformer_lens.components)": [[13, "transformer_lens.components.MLP"]], "ov (transformer_lens.components.attention property)": [[13, "transformer_lens.components.Attention.OV"]], "posembed (class in transformer_lens.components)": [[13, "transformer_lens.components.PosEmbed"]], "qk (transformer_lens.components.attention property)": [[13, "transformer_lens.components.Attention.QK"]], "rmsnorm (class in transformer_lens.components)": [[13, "transformer_lens.components.RMSNorm"]], "rmsnormpre (class in transformer_lens.components)": [[13, "transformer_lens.components.RMSNormPre"]], "tokentypeembed (class in transformer_lens.components)": [[13, "transformer_lens.components.TokenTypeEmbed"]], "transformerblock (class in transformer_lens.components)": [[13, "transformer_lens.components.TransformerBlock"]], "unembed (class in transformer_lens.components)": [[13, "transformer_lens.components.Unembed"]], "__init__() (transformer_lens.components.attention method)": [[13, "transformer_lens.components.Attention.__init__"]], "__init__() (transformer_lens.components.layernorm method)": [[13, "transformer_lens.components.LayerNorm.__init__"]], "__init__() (transformer_lens.components.layernormpre method)": [[13, "transformer_lens.components.LayerNormPre.__init__"]], "__init__() (transformer_lens.components.rmsnorm method)": [[13, "transformer_lens.components.RMSNorm.__init__"]], "__init__() (transformer_lens.components.rmsnormpre method)": [[13, "transformer_lens.components.RMSNormPre.__init__"]], "apply_causal_mask() (transformer_lens.components.attention method)": [[13, "transformer_lens.components.Attention.apply_causal_mask"]], "apply_rotary() (transformer_lens.components.attention method)": [[13, "transformer_lens.components.Attention.apply_rotary"]], "calculate_sin_cos_rotary() (transformer_lens.components.attention method)": [[13, "transformer_lens.components.Attention.calculate_sin_cos_rotary"]], "forward() (transformer_lens.components.attention method)": [[13, "transformer_lens.components.Attention.forward"]], "forward() (transformer_lens.components.bertblock method)": [[13, "transformer_lens.components.BertBlock.forward"]], "forward() (transformer_lens.components.bertembed method)": [[13, "transformer_lens.components.BertEmbed.forward"]], "forward() (transformer_lens.components.bertmlmhead method)": [[13, "transformer_lens.components.BertMLMHead.forward"]], "forward() (transformer_lens.components.embed method)": [[13, "transformer_lens.components.Embed.forward"]], "forward() (transformer_lens.components.gatedmlp method)": [[13, "transformer_lens.components.GatedMLP.forward"]], "forward() (transformer_lens.components.layernorm method)": [[13, "transformer_lens.components.LayerNorm.forward"]], "forward() (transformer_lens.components.layernormpre method)": [[13, "transformer_lens.components.LayerNormPre.forward"]], "forward() (transformer_lens.components.mlp method)": [[13, "transformer_lens.components.MLP.forward"]], "forward() (transformer_lens.components.posembed method)": [[13, "transformer_lens.components.PosEmbed.forward"]], "forward() (transformer_lens.components.rmsnorm method)": [[13, "transformer_lens.components.RMSNorm.forward"]], "forward() (transformer_lens.components.rmsnormpre method)": [[13, "transformer_lens.components.RMSNormPre.forward"]], "forward() (transformer_lens.components.tokentypeembed method)": [[13, "transformer_lens.components.TokenTypeEmbed.forward"]], "forward() (transformer_lens.components.transformerblock method)": [[13, "transformer_lens.components.TransformerBlock.forward"]], "forward() (transformer_lens.components.unembed method)": [[13, "transformer_lens.components.Unembed.forward"]], "rotate_every_two() (transformer_lens.components.attention method)": [[13, "transformer_lens.components.Attention.rotate_every_two"]], "transformer_lens.components": [[13, "module-transformer_lens.components"]], "ioidataset (class in transformer_lens.evals)": [[14, "transformer_lens.evals.IOIDataset"]], "evaluate() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.evaluate_on_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[14, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[14, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[14, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[14, "transformer_lens.evals.IOIDataset.get_sample"]], "induction_loss() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.induction_loss"]], "ioi_eval() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.ioi_eval"]], "make_code_data_loader() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.make_code_data_loader"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.make_wiki_data_loader"]], "sanity_check() (in module transformer_lens.evals)": [[14, "transformer_lens.evals.sanity_check"]], "transformer_lens.evals": [[14, "module-transformer_lens.evals"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[15, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "detect_head() (in module transformer_lens.head_detector)": [[15, "transformer_lens.head_detector.detect_head"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[15, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[15, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[15, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[15, "transformer_lens.head_detector.get_supported_heads"]], "transformer_lens.head_detector": [[15, "module-transformer_lens.head_detector"]], "hookpoint (class in transformer_lens.hook_points)": [[16, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[16, "transformer_lens.hook_points.HookedRootModule"]], "lenshandle (class in transformer_lens.hook_points)": [[16, "transformer_lens.hook_points.LensHandle"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[16, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[16, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[16, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[16, "id0"], [16, "transformer_lens.hook_points.LensHandle.context_level"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[16, "transformer_lens.hook_points.HookPoint.forward"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[16, "id1"], [16, "transformer_lens.hook_points.LensHandle.hook"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.hooks"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[16, "id2"], [16, "transformer_lens.hook_points.LensHandle.is_permanent"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[16, "transformer_lens.hook_points.HookPoint.layer"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[16, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[16, "transformer_lens.hook_points.HookedRootModule.setup"]], "transformer_lens.hook_points": [[16, "module-transformer_lens.hook_points"]], "config (class in transformer_lens.loading_from_pretrained)": [[17, "transformer_lens.loading_from_pretrained.Config"]], "model_aliases (in module transformer_lens.loading_from_pretrained)": [[17, "transformer_lens.loading_from_pretrained.MODEL_ALIASES"]], "official_model_names (in module transformer_lens.loading_from_pretrained)": [[17, "transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.debug"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[17, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[17, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[17, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.init_range"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[17, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "transformer_lens.loading_from_pretrained": [[17, "module-transformer_lens.loading_from_pretrained"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "append_attention_mask() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.append_attention_mask"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "freeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.freeze"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.frozen"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.frozen"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "previous_attention_mask (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.previous_attention_mask"]], "transformer_lens.past_key_value_caching": [[18, "module-transformer_lens.past_key_value_caching"]], "unfreeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[18, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.unfreeze"]], "generic_activation_patch() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.generic_activation_patch"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.get_act_patch_resid_pre"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[19, "transformer_lens.patching.layer_pos_patch_setter"]], "transformer_lens.patching": [[19, "module-transformer_lens.patching"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[20, "transformer_lens.train.HookedTransformerTrainConfig"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "train() (in module transformer_lens.train)": [[20, "transformer_lens.train.train"]], "transformer_lens.train": [[20, "module-transformer_lens.train"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[20, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[22, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[22, "transformer_lens.utilities.devices.move_to_and_update_config"]], "transformer_lens.utilities.devices": [[22, "module-transformer_lens.utilities.devices"]], "locallyoverridendefaults (class in transformer_lens.utils)": [[23, "transformer_lens.utils.LocallyOverridenDefaults"]], "slice (class in transformer_lens.utils)": [[23, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[23, "transformer_lens.utils.SliceInput"]], "__init__() (transformer_lens.utils.locallyoverridendefaults method)": [[23, "transformer_lens.utils.LocallyOverridenDefaults.__init__"]], "__init__() (transformer_lens.utils.slice method)": [[23, "transformer_lens.utils.Slice.__init__"]], "apply() (transformer_lens.utils.slice method)": [[23, "transformer_lens.utils.Slice.apply"]], "composition_scores() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.composition_scores"]], "download_file_from_hf() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.download_file_from_hf"]], "gelu_fast() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.gelu_new"]], "get_act_name() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_act_name"]], "get_attention_mask() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_attention_mask"]], "get_corner() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_corner"]], "get_cumsum_along_dim() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_cumsum_along_dim"]], "get_dataset() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_dataset"]], "get_device() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_device"]], "get_input_with_manually_prepended_bos() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_input_with_manually_prepended_bos"]], "get_nested_attr() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_nested_attr"]], "get_offset_position_ids() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_offset_position_ids"]], "get_tokenizer_with_bos() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_tokenizer_with_bos"]], "get_tokens_with_bos_removed() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.get_tokens_with_bos_removed"]], "indices() (transformer_lens.utils.slice method)": [[23, "transformer_lens.utils.Slice.indices"]], "is_lower_triangular() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.is_lower_triangular"]], "is_square() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.is_square"]], "keep_single_column() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.keep_single_column"]], "lm_accuracy() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.lm_cross_entropy_loss"]], "override_or_use_default_value() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.override_or_use_default_value"]], "print_gpu_mem() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.print_gpu_mem"]], "remove_batch_dim() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.remove_batch_dim"]], "sample_logits() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.sample_logits"]], "set_nested_attr() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.set_nested_attr"]], "solu() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.solu"]], "test_prompt() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.test_prompt"]], "to_numpy() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.to_numpy"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.tokenize_and_concatenate"]], "transformer_lens.utils": [[23, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[23, "transformer_lens.utils.transpose"]]}})